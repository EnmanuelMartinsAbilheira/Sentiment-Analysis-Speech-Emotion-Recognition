{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Read the CSV file\n",
    "df = pd.read_csv('dataset.csv')\n",
    "\n",
    "# Shuffle the data\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify Class balance \"Type\" column\n",
    "df['Type'].value_counts()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify Class balance \"Factual/Subjective\" column\n",
    "df['Factual/Subjective'].value_counts()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify Class balance \"Sentiment\" column\n",
    "df['Sentiment'].value_counts()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify Class balance \"Type\" column\n",
    "print(df['Type'].value_counts())\n",
    "print(\"-----------------------------\")\n",
    "# Verify Class balance \"Factual/Subjective\" column\n",
    "print(df['Factual/Subjective'].value_counts())\n",
    "print(\"-----------------------------\")\n",
    "# Verify Class balance \"Sentiment\" column\n",
    "print(df['Sentiment'].value_counts())\n",
    "print(\"-----------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify and print all repeated values in the column Sentence\n",
    "print(df['Sentence'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicates\n",
    "df = df.drop_duplicates(subset='Sentence')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify Class balance \"Type\" column\n",
    "print(df['Type'].value_counts())\n",
    "print(\"-----------------------------\")\n",
    "# Verify Class balance \"Factual/Subjective\" column\n",
    "print(df['Factual/Subjective'].value_counts())\n",
    "print(\"-----------------------------\")\n",
    "# Verify Class balance \"Sentiment\" column\n",
    "print(df['Sentiment'].value_counts())\n",
    "print(\"-----------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implement textblob library to calculate the polarity of each sentence\n",
    "from textblob import TextBlob\n",
    "df['polarity'] = df['Sentence'].apply(lambda x: TextBlob(x).sentiment.polarity)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# textblob library to calculate the subjectivity of each sentence\n",
    "df['subjectivity'] = df['Sentence'].apply(lambda x: TextBlob(x).sentiment.subjectivity)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implement textblob to make the polarity and subjectivity columns more readable\n",
    "def sentiment(x):\n",
    "    if x < 0:\n",
    "        return 'Negative'\n",
    "    elif x == 0:\n",
    "        return 'Neutral'\n",
    "    else:\n",
    "        return 'Positive'\n",
    "    \n",
    "df['polarity'] = df['polarity'].apply(lambda x: sentiment(x))\n",
    "df['subjectivity'] = df['subjectivity'].apply(lambda x: sentiment(x))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize sentence embedding model\n",
    "model = SentenceTransformer(\"sentence-transformers/all-mpnet-base-v2\")\n",
    "\n",
    "# Encode sentences into embeddings\n",
    "embeddings = model.encode(df[\"Sentence\"].tolist())\n",
    "\n",
    "# Label encoding\n",
    "type_mapping = {\"Affirmation\": 0, \"Negation\": 1}\n",
    "fact_subj_mapping = {\"Factual\": 0, \"Subjective\": 1}\n",
    "sentiment_mapping = {\"Sadness\": 0, \"Anger\": 1, \"Neutral\": 2, \"Happiness\": 3, \"Euphoria\": 4}\n",
    "\n",
    "df[\"Type\"] = df[\"Type\"].map(type_mapping).fillna(-1).astype(int)\n",
    "df[\"Factual/Subjective\"] = df[\"Factual/Subjective\"].map(fact_subj_mapping).fillna(-1).astype(int)\n",
    "df[\"Sentiment\"] = df[\"Sentiment\"].map(sentiment_mapping).fillna(-1).astype(int)\n",
    "\n",
    "# Convert labels to NumPy arrays\n",
    "type_labels = df[\"Type\"].values\n",
    "fact_subj_labels = df[\"Factual/Subjective\"].values\n",
    "sentiment_labels = df[\"Sentiment\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stratified Train-Test Split (based on Sentiment)\n",
    "X_train, X_test, y_type_train, y_type_test, y_fact_train, y_fact_test, y_sent_train, y_sent_test = train_test_split(\n",
    "    embeddings, type_labels, fact_subj_labels, sentiment_labels,\n",
    "    test_size=0.2, random_state=42, stratify=sentiment_labels  # Ensuring class balance\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter Grid for XGBoost\n",
    "param_grid = {\n",
    "    \"n_estimators\": [50, 100, 200, 500],\n",
    "    \"max_depth\": [3, 5, 7, 10],\n",
    "    \"learning_rate\": [0.01, 0.1, 0.3],\n",
    "    \"subsample\": [0.7, 1.0]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to train and evaluate XGBoost with hyperparameter search\n",
    "def train_xgboost(X_train, y_train, X_test, y_test, name):\n",
    "    model = XGBClassifier(eval_metric=\"mlogloss\")\n",
    "    grid_search = GridSearchCV(model, param_grid, cv=3, scoring=\"accuracy\", n_jobs=-1)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    best_model = grid_search.best_estimator_\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    print(f\"Best XGBoost Model for {name}: {grid_search.best_params_}\")\n",
    "    print(f\"Accuracy for {name}: {acc:.4f}\\n\")\n",
    "\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and evaluate XGBoost models\n",
    "type_model = train_xgboost(X_train, y_type_train, X_test, y_type_test, \"Type Classification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fact_model = train_xgboost(X_train, y_fact_train, X_test, y_fact_test, \"Factual/Subjective Classification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_model = train_xgboost(X_train, y_sent_train, X_test, y_sent_test, \"Sentiment Classification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisper\n",
    "\n",
    "# Carregar o modelo (podes usar \"tiny\", \"base\", \"small\", \"medium\", \"large\")\n",
    "model = whisper.load_model(\"small\")\n",
    "\n",
    "# Transcrever o Ã¡udio\n",
    "audio_path = \"audio.mp3\"  # Substituir pelo nome do teu ficheiro\n",
    "result = model.transcribe(audio_path)\n",
    "\n",
    "# Exibir o texto reconhecido\n",
    "print(\"Texto reconhecido:\")\n",
    "print(result[\"text\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.transcribe(audio_path, language=\"pt\", fp16=False)  # ForÃ§a uso de float32 para CPUs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sounddevice as sd\n",
    "import numpy as np\n",
    "import wave\n",
    "import time\n",
    "from pydub import AudioSegment\n",
    "import whisper\n",
    "\n",
    "# ConfiguraÃ§Ã£o da gravaÃ§Ã£o\n",
    "SAMPLE_RATE = 44100  # Qualidade de Ã¡udio\n",
    "CHANNELS = 1         # Mono\n",
    "\n",
    "# VariÃ¡vel global para controlar a gravaÃ§Ã£o\n",
    "recording = False\n",
    "\n",
    "def start_recording(filename=\"output.wav\", duration=None):\n",
    "    \"\"\"ComeÃ§a a gravar Ã¡udio e guarda como WAV\"\"\"\n",
    "    global recording\n",
    "    recording = True\n",
    "    print(\"ðŸŽ¤ Gravando... Pressiona Ctrl+C para parar.\")\n",
    "    \n",
    "    frames = []\n",
    "    \n",
    "    def callback(indata, frames_count, time_info, status):\n",
    "        if recording:\n",
    "            frames.append(indata.copy())\n",
    "\n",
    "    with sd.InputStream(samplerate=SAMPLE_RATE, channels=CHANNELS, callback=callback):\n",
    "        if duration:\n",
    "            time.sleep(duration)\n",
    "            stop_recording(filename, frames)\n",
    "        else:\n",
    "            try:\n",
    "                while recording:\n",
    "                    time.sleep(0.1)\n",
    "            except KeyboardInterrupt:\n",
    "                stop_recording(filename, frames)\n",
    "\n",
    "def stop_recording(filename, frames):\n",
    "    \"\"\"Para a gravaÃ§Ã£o e salva o arquivo como WAV\"\"\"\n",
    "    global recording\n",
    "    recording = False\n",
    "    print(\"â¹ï¸ GravaÃ§Ã£o terminada. Salvando arquivo...\")\n",
    "\n",
    "    # Converter para NumPy array\n",
    "    audio_data = np.concatenate(frames, axis=0)\n",
    "\n",
    "    # Salvar como WAV\n",
    "    with wave.open(filename, \"wb\") as wf:\n",
    "        wf.setnchannels(CHANNELS)\n",
    "        wf.setsampwidth(2)\n",
    "        wf.setframerate(SAMPLE_RATE)\n",
    "        wf.writeframes((audio_data * 32767).astype(np.int16).tobytes())\n",
    "\n",
    "    # Converter para MP3\n",
    "    convert_to_mp3(filename)\n",
    "    \n",
    "def convert_to_mp3(wav_filename):\n",
    "    \"\"\"Converte um arquivo WAV para MP3\"\"\"\n",
    "    mp3_filename = wav_filename.replace(\".wav\", \".mp3\")\n",
    "    audio = AudioSegment.from_wav(wav_filename)\n",
    "    audio.export(mp3_filename, format=\"mp3\")\n",
    "    print(f\"ðŸŽµ Arquivo salvo como {mp3_filename}\")\n",
    "    return mp3_filename\n",
    "\n",
    "\n",
    "def transcribe_audio(audio_path):\n",
    "    \"\"\"Usa Whisper para transcrever o Ã¡udio\"\"\"\n",
    "    print(\"ðŸ“ Transcrevendo o Ã¡udio...\")\n",
    "    model = whisper.load_model(\"small\")\n",
    "    result = model.transcribe(audio_path, language=\"en\")\n",
    "    \n",
    "    print(\"ðŸ“œ TranscriÃ§Ã£o:\")\n",
    "    print(result[\"text\"])\n",
    "\n",
    "# Executar gravaÃ§Ã£o e transcriÃ§Ã£o\n",
    "if __name__ == \"__main__\":\n",
    "    audio_file = \"output.wav\"\n",
    "    start_recording(audio_file)  # Pressiona Ctrl+C para parar a gravaÃ§Ã£o\n",
    "    mp3_file = audio_file.replace(\".wav\", \".mp3\")\n",
    "    transcribe_audio(mp3_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“ Transcrevendo o Ã¡udio...\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 2] El sistema no puede encontrar el archivo especificado",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m#start_recording(audio_file)  # Pressiona Ctrl+C para parar a gravaÃ§Ã£o\u001b[39;00m\n\u001b[32m     14\u001b[39m mp3_file = audio_file.replace(\u001b[33m\"\u001b[39m\u001b[33m.wav\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m.mp3\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m \u001b[43mtranscribe_audio\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmp3_file\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 5\u001b[39m, in \u001b[36mtranscribe_audio\u001b[39m\u001b[34m(audio_path)\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mðŸ“ Transcrevendo o Ã¡udio...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      4\u001b[39m model = whisper.load_model(\u001b[33m\"\u001b[39m\u001b[33msmall\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m result = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtranscribe\u001b[49m\u001b[43m(\u001b[49m\u001b[43maudio_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlanguage\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43men\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mðŸ“œ TranscriÃ§Ã£o:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      8\u001b[39m \u001b[38;5;28mprint\u001b[39m(result[\u001b[33m\"\u001b[39m\u001b[33mtext\u001b[39m\u001b[33m\"\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\eel20\\Desktop\\Sentiment-Analysis-Speech-Emotion-Recognition\\.venv\\Lib\\site-packages\\whisper\\transcribe.py:133\u001b[39m, in \u001b[36mtranscribe\u001b[39m\u001b[34m(model, audio, verbose, temperature, compression_ratio_threshold, logprob_threshold, no_speech_threshold, condition_on_previous_text, initial_prompt, word_timestamps, prepend_punctuations, append_punctuations, clip_timestamps, hallucination_silence_threshold, **decode_options)\u001b[39m\n\u001b[32m    130\u001b[39m     decode_options[\u001b[33m\"\u001b[39m\u001b[33mfp16\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    132\u001b[39m \u001b[38;5;66;03m# Pad 30-seconds of silence to the input audio, for slicing\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m133\u001b[39m mel = \u001b[43mlog_mel_spectrogram\u001b[49m\u001b[43m(\u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdims\u001b[49m\u001b[43m.\u001b[49m\u001b[43mn_mels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mN_SAMPLES\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    134\u001b[39m content_frames = mel.shape[-\u001b[32m1\u001b[39m] - N_FRAMES\n\u001b[32m    135\u001b[39m content_duration = \u001b[38;5;28mfloat\u001b[39m(content_frames * HOP_LENGTH / SAMPLE_RATE)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\eel20\\Desktop\\Sentiment-Analysis-Speech-Emotion-Recognition\\.venv\\Lib\\site-packages\\whisper\\audio.py:140\u001b[39m, in \u001b[36mlog_mel_spectrogram\u001b[39m\u001b[34m(audio, n_mels, padding, device)\u001b[39m\n\u001b[32m    138\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch.is_tensor(audio):\n\u001b[32m    139\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(audio, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m140\u001b[39m         audio = \u001b[43mload_audio\u001b[49m\u001b[43m(\u001b[49m\u001b[43maudio\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    141\u001b[39m     audio = torch.from_numpy(audio)\n\u001b[32m    143\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m device \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\eel20\\Desktop\\Sentiment-Analysis-Speech-Emotion-Recognition\\.venv\\Lib\\site-packages\\whisper\\audio.py:58\u001b[39m, in \u001b[36mload_audio\u001b[39m\u001b[34m(file, sr)\u001b[39m\n\u001b[32m     56\u001b[39m \u001b[38;5;66;03m# fmt: on\u001b[39;00m\n\u001b[32m     57\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m58\u001b[39m     out = \u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcmd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcapture_output\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m.stdout\n\u001b[32m     59\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m CalledProcessError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     60\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFailed to load audio: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me.stderr.decode()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Python311\\Lib\\subprocess.py:548\u001b[39m, in \u001b[36mrun\u001b[39m\u001b[34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[39m\n\u001b[32m    545\u001b[39m     kwargs[\u001b[33m'\u001b[39m\u001b[33mstdout\u001b[39m\u001b[33m'\u001b[39m] = PIPE\n\u001b[32m    546\u001b[39m     kwargs[\u001b[33m'\u001b[39m\u001b[33mstderr\u001b[39m\u001b[33m'\u001b[39m] = PIPE\n\u001b[32m--> \u001b[39m\u001b[32m548\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mpopenargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m process:\n\u001b[32m    549\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    550\u001b[39m         stdout, stderr = process.communicate(\u001b[38;5;28minput\u001b[39m, timeout=timeout)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Python311\\Lib\\subprocess.py:1024\u001b[39m, in \u001b[36mPopen.__init__\u001b[39m\u001b[34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask, pipesize, process_group)\u001b[39m\n\u001b[32m   1020\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.text_mode:\n\u001b[32m   1021\u001b[39m             \u001b[38;5;28mself\u001b[39m.stderr = io.TextIOWrapper(\u001b[38;5;28mself\u001b[39m.stderr,\n\u001b[32m   1022\u001b[39m                     encoding=encoding, errors=errors)\n\u001b[32m-> \u001b[39m\u001b[32m1024\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_execute_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecutable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreexec_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclose_fds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1025\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mpass_fds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcwd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1026\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mstartupinfo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreationflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshell\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1027\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mp2cread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp2cwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1028\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mc2pread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc2pwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1029\u001b[39m \u001b[43m                        \u001b[49m\u001b[43merrread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1030\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mrestore_signals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1031\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mgid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mumask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1032\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mstart_new_session\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprocess_group\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1033\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[32m   1034\u001b[39m     \u001b[38;5;66;03m# Cleanup if the child failed starting.\u001b[39;00m\n\u001b[32m   1035\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mfilter\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m, (\u001b[38;5;28mself\u001b[39m.stdin, \u001b[38;5;28mself\u001b[39m.stdout, \u001b[38;5;28mself\u001b[39m.stderr)):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Python311\\Lib\\subprocess.py:1509\u001b[39m, in \u001b[36mPopen._execute_child\u001b[39m\u001b[34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, unused_restore_signals, unused_gid, unused_gids, unused_uid, unused_umask, unused_start_new_session, unused_process_group)\u001b[39m\n\u001b[32m   1507\u001b[39m \u001b[38;5;66;03m# Start the process\u001b[39;00m\n\u001b[32m   1508\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1509\u001b[39m     hp, ht, pid, tid = _winapi.CreateProcess(executable, args,\n\u001b[32m   1510\u001b[39m                              \u001b[38;5;66;03m# no special security\u001b[39;00m\n\u001b[32m   1511\u001b[39m                              \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1512\u001b[39m                              \u001b[38;5;28mint\u001b[39m(\u001b[38;5;129;01mnot\u001b[39;00m close_fds),\n\u001b[32m   1513\u001b[39m                              creationflags,\n\u001b[32m   1514\u001b[39m                              env,\n\u001b[32m   1515\u001b[39m                              cwd,\n\u001b[32m   1516\u001b[39m                              startupinfo)\n\u001b[32m   1517\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m   1518\u001b[39m     \u001b[38;5;66;03m# Child is launched. Close the parent's copy of those pipe\u001b[39;00m\n\u001b[32m   1519\u001b[39m     \u001b[38;5;66;03m# handles that only the child should have open.  You need\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1522\u001b[39m     \u001b[38;5;66;03m# pipe will not close when the child process exits and the\u001b[39;00m\n\u001b[32m   1523\u001b[39m     \u001b[38;5;66;03m# ReadFile will hang.\u001b[39;00m\n\u001b[32m   1524\u001b[39m     \u001b[38;5;28mself\u001b[39m._close_pipe_fds(p2cread, p2cwrite,\n\u001b[32m   1525\u001b[39m                          c2pread, c2pwrite,\n\u001b[32m   1526\u001b[39m                          errread, errwrite)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [WinError 2] El sistema no puede encontrar el archivo especificado"
     ]
    }
   ],
   "source": [
    "\n",
    "def transcribe_audio(audio_path):\n",
    "    \"\"\"Usa Whisper para transcrever o Ã¡udio\"\"\"\n",
    "    print(\"ðŸ“ Transcrevendo o Ã¡udio...\")\n",
    "    model = whisper.load_model(\"small\")\n",
    "    result = model.transcribe(audio_path, language=\"en\")\n",
    "    \n",
    "    print(\"ðŸ“œ TranscriÃ§Ã£o:\")\n",
    "    print(result[\"text\"])\n",
    "\n",
    "# Executar gravaÃ§Ã£o e transcriÃ§Ã£o\n",
    "if __name__ == \"__main__\":\n",
    "    audio_file = \"output.wav\"\n",
    "    #start_recording(audio_file)  # Pressiona Ctrl+C para parar a gravaÃ§Ã£o\n",
    "    mp3_file = audio_file.replace(\".wav\", \".mp3\")\n",
    "    transcribe_audio(mp3_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŽ¤ Gravando... (10 segundos)\n",
      "â¹ï¸ GravaÃ§Ã£o concluÃ­da.\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 2] El sistema no puede encontrar el archivo especificado",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 50\u001b[39m\n\u001b[32m     48\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m     49\u001b[39m     audio_file = record_audio(\u001b[33m\"\u001b[39m\u001b[33moutput.wav\u001b[39m\u001b[33m\"\u001b[39m)  \u001b[38;5;66;03m# Grava automaticamente por 10 segundos\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m50\u001b[39m     mp3_file = \u001b[43mconvert_to_mp3\u001b[49m\u001b[43m(\u001b[49m\u001b[43maudio_file\u001b[49m\u001b[43m)\u001b[49m    \u001b[38;5;66;03m# Converte para MP3\u001b[39;00m\n\u001b[32m     51\u001b[39m     transcribe_audio(mp3_file)               \u001b[38;5;66;03m# Transcreve o Ã¡udio\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 34\u001b[39m, in \u001b[36mconvert_to_mp3\u001b[39m\u001b[34m(wav_filename)\u001b[39m\n\u001b[32m     32\u001b[39m mp3_filename = wav_filename.replace(\u001b[33m\"\u001b[39m\u001b[33m.wav\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m.mp3\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     33\u001b[39m audio = AudioSegment.from_wav(wav_filename)\n\u001b[32m---> \u001b[39m\u001b[32m34\u001b[39m \u001b[43maudio\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexport\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmp3_filename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmp3\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     35\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mðŸŽµ Arquivo salvo como \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmp3_filename\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     36\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m mp3_filename\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\eel20\\Desktop\\Sentiment-Analysis-Speech-Emotion-Recognition\\.venv\\Lib\\site-packages\\pydub\\audio_segment.py:963\u001b[39m, in \u001b[36mAudioSegment.export\u001b[39m\u001b[34m(self, out_f, format, codec, bitrate, parameters, tags, id3v2_version, cover)\u001b[39m\n\u001b[32m    961\u001b[39m \u001b[38;5;66;03m# read stdin / write stdout\u001b[39;00m\n\u001b[32m    962\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(os.devnull, \u001b[33m'\u001b[39m\u001b[33mrb\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m devnull:\n\u001b[32m--> \u001b[39m\u001b[32m963\u001b[39m     p = \u001b[43msubprocess\u001b[49m\u001b[43m.\u001b[49m\u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconversion_command\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstdin\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevnull\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstdout\u001b[49m\u001b[43m=\u001b[49m\u001b[43msubprocess\u001b[49m\u001b[43m.\u001b[49m\u001b[43mPIPE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstderr\u001b[49m\u001b[43m=\u001b[49m\u001b[43msubprocess\u001b[49m\u001b[43m.\u001b[49m\u001b[43mPIPE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    964\u001b[39m p_out, p_err = p.communicate()\n\u001b[32m    966\u001b[39m log_subprocess_output(p_out)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Python311\\Lib\\subprocess.py:1024\u001b[39m, in \u001b[36mPopen.__init__\u001b[39m\u001b[34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask, pipesize, process_group)\u001b[39m\n\u001b[32m   1020\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.text_mode:\n\u001b[32m   1021\u001b[39m             \u001b[38;5;28mself\u001b[39m.stderr = io.TextIOWrapper(\u001b[38;5;28mself\u001b[39m.stderr,\n\u001b[32m   1022\u001b[39m                     encoding=encoding, errors=errors)\n\u001b[32m-> \u001b[39m\u001b[32m1024\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_execute_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecutable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreexec_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclose_fds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1025\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mpass_fds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcwd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1026\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mstartupinfo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreationflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshell\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1027\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mp2cread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp2cwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1028\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mc2pread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc2pwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1029\u001b[39m \u001b[43m                        \u001b[49m\u001b[43merrread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1030\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mrestore_signals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1031\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mgid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mumask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1032\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mstart_new_session\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprocess_group\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1033\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[32m   1034\u001b[39m     \u001b[38;5;66;03m# Cleanup if the child failed starting.\u001b[39;00m\n\u001b[32m   1035\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mfilter\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m, (\u001b[38;5;28mself\u001b[39m.stdin, \u001b[38;5;28mself\u001b[39m.stdout, \u001b[38;5;28mself\u001b[39m.stderr)):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Python311\\Lib\\subprocess.py:1509\u001b[39m, in \u001b[36mPopen._execute_child\u001b[39m\u001b[34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, unused_restore_signals, unused_gid, unused_gids, unused_uid, unused_umask, unused_start_new_session, unused_process_group)\u001b[39m\n\u001b[32m   1507\u001b[39m \u001b[38;5;66;03m# Start the process\u001b[39;00m\n\u001b[32m   1508\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1509\u001b[39m     hp, ht, pid, tid = \u001b[43m_winapi\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCreateProcess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexecutable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1510\u001b[39m \u001b[43m                             \u001b[49m\u001b[38;5;66;43;03m# no special security\u001b[39;49;00m\n\u001b[32m   1511\u001b[39m \u001b[43m                             \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1512\u001b[39m \u001b[43m                             \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mclose_fds\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1513\u001b[39m \u001b[43m                             \u001b[49m\u001b[43mcreationflags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1514\u001b[39m \u001b[43m                             \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1515\u001b[39m \u001b[43m                             \u001b[49m\u001b[43mcwd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1516\u001b[39m \u001b[43m                             \u001b[49m\u001b[43mstartupinfo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1517\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m   1518\u001b[39m     \u001b[38;5;66;03m# Child is launched. Close the parent's copy of those pipe\u001b[39;00m\n\u001b[32m   1519\u001b[39m     \u001b[38;5;66;03m# handles that only the child should have open.  You need\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1522\u001b[39m     \u001b[38;5;66;03m# pipe will not close when the child process exits and the\u001b[39;00m\n\u001b[32m   1523\u001b[39m     \u001b[38;5;66;03m# ReadFile will hang.\u001b[39;00m\n\u001b[32m   1524\u001b[39m     \u001b[38;5;28mself\u001b[39m._close_pipe_fds(p2cread, p2cwrite,\n\u001b[32m   1525\u001b[39m                          c2pread, c2pwrite,\n\u001b[32m   1526\u001b[39m                          errread, errwrite)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [WinError 2] El sistema no puede encontrar el archivo especificado"
     ]
    }
   ],
   "source": [
    "import sounddevice as sd\n",
    "import numpy as np\n",
    "import wave\n",
    "import time\n",
    "from pydub import AudioSegment\n",
    "import whisper\n",
    "\n",
    "# ConfiguraÃ§Ã£o da gravaÃ§Ã£o\n",
    "SAMPLE_RATE = 44100  # Qualidade do Ã¡udio\n",
    "CHANNELS = 1         # Mono\n",
    "DURATION = 10        # Tempo mÃ¡ximo de gravaÃ§Ã£o (segundos)\n",
    "\n",
    "def record_audio(filename=\"output.wav\", duration=DURATION):\n",
    "    \"\"\"Grava Ã¡udio por um tempo mÃ¡ximo e salva como WAV\"\"\"\n",
    "    print(f\"ðŸŽ¤ Gravando... ({duration} segundos)\")\n",
    "    \n",
    "    audio_data = sd.rec(int(duration * SAMPLE_RATE), samplerate=SAMPLE_RATE, channels=CHANNELS, dtype=np.int16)\n",
    "    sd.wait()  # Espera a gravaÃ§Ã£o terminar\n",
    "    \n",
    "    # Salvar como WAV\n",
    "    with wave.open(filename, \"wb\") as wf:\n",
    "        wf.setnchannels(CHANNELS)\n",
    "        wf.setsampwidth(2)\n",
    "        wf.setframerate(SAMPLE_RATE)\n",
    "        wf.writeframes(audio_data.tobytes())\n",
    "\n",
    "    print(\"â¹ï¸ GravaÃ§Ã£o concluÃ­da.\")\n",
    "    return filename\n",
    "\n",
    "def convert_to_mp3(wav_filename):\n",
    "    \"\"\"Converte um arquivo WAV para MP3\"\"\"\n",
    "    mp3_filename = wav_filename.replace(\".wav\", \".mp3\")\n",
    "    audio = AudioSegment.from_wav(wav_filename)\n",
    "    audio.export(mp3_filename, format=\"mp3\")\n",
    "    print(f\"ðŸŽµ Arquivo salvo como {mp3_filename}\")\n",
    "    return mp3_filename\n",
    "\n",
    "def transcribe_audio(audio_path):\n",
    "    \"\"\"Usa Whisper para transcrever o Ã¡udio\"\"\"\n",
    "    print(\"ðŸ“ Transcrevendo o Ã¡udio...\")\n",
    "    model = whisper.load_model(\"small\")\n",
    "    result = model.transcribe(audio_path, language=\"en\")\n",
    "    \n",
    "    print(\"ðŸ“œ TranscriÃ§Ã£o:\")\n",
    "    print(result[\"text\"])\n",
    "\n",
    "# Executar gravaÃ§Ã£o e transcriÃ§Ã£o\n",
    "if __name__ == \"__main__\":\n",
    "    audio_file = record_audio(\"output.wav\")  # Grava automaticamente por 10 segundos\n",
    "    mp3_file = convert_to_mp3(audio_file)    # Converte para MP3\n",
    "    transcribe_audio(mp3_file)               # Transcreve o Ã¡udio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… O arquivo WAV existe. Convertendo para MP3...\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 2] El sistema no puede encontrar el archivo especificado",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[32m     12\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mâœ… O arquivo WAV existe. Convertendo para MP3...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     14\u001b[39m     audio = AudioSegment.from_wav(wav_file)\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m     \u001b[43maudio\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexport\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43moutput.mp3\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmp3\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     16\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mâœ… ConversÃ£o concluÃ­da!\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\eel20\\Desktop\\Sentiment-Analysis-Speech-Emotion-Recognition\\.venv\\Lib\\site-packages\\pydub\\audio_segment.py:963\u001b[39m, in \u001b[36mAudioSegment.export\u001b[39m\u001b[34m(self, out_f, format, codec, bitrate, parameters, tags, id3v2_version, cover)\u001b[39m\n\u001b[32m    961\u001b[39m \u001b[38;5;66;03m# read stdin / write stdout\u001b[39;00m\n\u001b[32m    962\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(os.devnull, \u001b[33m'\u001b[39m\u001b[33mrb\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m devnull:\n\u001b[32m--> \u001b[39m\u001b[32m963\u001b[39m     p = \u001b[43msubprocess\u001b[49m\u001b[43m.\u001b[49m\u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconversion_command\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstdin\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevnull\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstdout\u001b[49m\u001b[43m=\u001b[49m\u001b[43msubprocess\u001b[49m\u001b[43m.\u001b[49m\u001b[43mPIPE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstderr\u001b[49m\u001b[43m=\u001b[49m\u001b[43msubprocess\u001b[49m\u001b[43m.\u001b[49m\u001b[43mPIPE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    964\u001b[39m p_out, p_err = p.communicate()\n\u001b[32m    966\u001b[39m log_subprocess_output(p_out)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Python311\\Lib\\subprocess.py:1024\u001b[39m, in \u001b[36mPopen.__init__\u001b[39m\u001b[34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask, pipesize, process_group)\u001b[39m\n\u001b[32m   1020\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.text_mode:\n\u001b[32m   1021\u001b[39m             \u001b[38;5;28mself\u001b[39m.stderr = io.TextIOWrapper(\u001b[38;5;28mself\u001b[39m.stderr,\n\u001b[32m   1022\u001b[39m                     encoding=encoding, errors=errors)\n\u001b[32m-> \u001b[39m\u001b[32m1024\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_execute_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecutable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreexec_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclose_fds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1025\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mpass_fds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcwd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1026\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mstartupinfo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreationflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshell\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1027\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mp2cread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp2cwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1028\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mc2pread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc2pwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1029\u001b[39m \u001b[43m                        \u001b[49m\u001b[43merrread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1030\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mrestore_signals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1031\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mgid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mumask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1032\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mstart_new_session\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprocess_group\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1033\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[32m   1034\u001b[39m     \u001b[38;5;66;03m# Cleanup if the child failed starting.\u001b[39;00m\n\u001b[32m   1035\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mfilter\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m, (\u001b[38;5;28mself\u001b[39m.stdin, \u001b[38;5;28mself\u001b[39m.stdout, \u001b[38;5;28mself\u001b[39m.stderr)):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Python311\\Lib\\subprocess.py:1509\u001b[39m, in \u001b[36mPopen._execute_child\u001b[39m\u001b[34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, unused_restore_signals, unused_gid, unused_gids, unused_uid, unused_umask, unused_start_new_session, unused_process_group)\u001b[39m\n\u001b[32m   1507\u001b[39m \u001b[38;5;66;03m# Start the process\u001b[39;00m\n\u001b[32m   1508\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1509\u001b[39m     hp, ht, pid, tid = _winapi.CreateProcess(executable, args,\n\u001b[32m   1510\u001b[39m                              \u001b[38;5;66;03m# no special security\u001b[39;00m\n\u001b[32m   1511\u001b[39m                              \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1512\u001b[39m                              \u001b[38;5;28mint\u001b[39m(\u001b[38;5;129;01mnot\u001b[39;00m close_fds),\n\u001b[32m   1513\u001b[39m                              creationflags,\n\u001b[32m   1514\u001b[39m                              env,\n\u001b[32m   1515\u001b[39m                              cwd,\n\u001b[32m   1516\u001b[39m                              startupinfo)\n\u001b[32m   1517\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m   1518\u001b[39m     \u001b[38;5;66;03m# Child is launched. Close the parent's copy of those pipe\u001b[39;00m\n\u001b[32m   1519\u001b[39m     \u001b[38;5;66;03m# handles that only the child should have open.  You need\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1522\u001b[39m     \u001b[38;5;66;03m# pipe will not close when the child process exits and the\u001b[39;00m\n\u001b[32m   1523\u001b[39m     \u001b[38;5;66;03m# ReadFile will hang.\u001b[39;00m\n\u001b[32m   1524\u001b[39m     \u001b[38;5;28mself\u001b[39m._close_pipe_fds(p2cread, p2cwrite,\n\u001b[32m   1525\u001b[39m                          c2pread, c2pwrite,\n\u001b[32m   1526\u001b[39m                          errread, errwrite)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [WinError 2] El sistema no puede encontrar el archivo especificado"
     ]
    }
   ],
   "source": [
    "import whisper\n",
    "import os\n",
    "\n",
    "# Carregar o modelo (podes usar \"tiny\", \"base\", \"small\", \"medium\", \"large\")\n",
    "model = whisper.load_model(\"small\")\n",
    "\n",
    "from pydub import AudioSegment\n",
    "\n",
    "# Testar se o arquivo WAV foi gravado corretamente antes da conversÃ£o\n",
    "wav_file = \"output.wav\"\n",
    "if os.path.exists(wav_file):\n",
    "    print(\"âœ… O arquivo WAV existe. Convertendo para MP3...\")\n",
    "    \n",
    "    audio = AudioSegment.from_wav(wav_file)\n",
    "    audio.export(\"output.mp3\", format=\"mp3\")\n",
    "    print(\"âœ… ConversÃ£o concluÃ­da!\")\n",
    "else:\n",
    "    print(\"âŒ O arquivo WAV NÃƒO foi encontrado.\")\n",
    "\n",
    "\n",
    "#result = model.transcribe(audio_path)\n",
    "\n",
    "# Exibir o texto reconhecido\n",
    "print(\"Texto reconhecido:\")\n",
    "print(result[\"text\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŽ™ï¸ Gravando... Fale algo!\n",
      "âœ… Ãudio salvo como output.wav\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 2] El sistema no puede encontrar el archivo especificado",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 42\u001b[39m\n\u001b[32m     40\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m     41\u001b[39m     wav_file = record_audio(duration=\u001b[32m5\u001b[39m)  \u001b[38;5;66;03m# Grava por 5 segundos\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m     mp3_file = \u001b[43mconvert_to_mp3\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwav_file\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Converte para MP3\u001b[39;00m\n\u001b[32m     43\u001b[39m     transcribe_audio(mp3_file)  \u001b[38;5;66;03m# Transcreve com Whisper\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 27\u001b[39m, in \u001b[36mconvert_to_mp3\u001b[39m\u001b[34m(wav_filename)\u001b[39m\n\u001b[32m     25\u001b[39m mp3_filename = wav_filename.replace(\u001b[33m\"\u001b[39m\u001b[33m.wav\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m.mp3\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     26\u001b[39m audio = AudioSegment.from_wav(wav_filename)\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m \u001b[43maudio\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexport\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmp3_filename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmp3\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     28\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mðŸŽµ Arquivo convertido para \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmp3_filename\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     29\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m mp3_filename\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\eel20\\Desktop\\Sentiment-Analysis-Speech-Emotion-Recognition\\.venv\\Lib\\site-packages\\pydub\\audio_segment.py:963\u001b[39m, in \u001b[36mAudioSegment.export\u001b[39m\u001b[34m(self, out_f, format, codec, bitrate, parameters, tags, id3v2_version, cover)\u001b[39m\n\u001b[32m    961\u001b[39m \u001b[38;5;66;03m# read stdin / write stdout\u001b[39;00m\n\u001b[32m    962\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(os.devnull, \u001b[33m'\u001b[39m\u001b[33mrb\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m devnull:\n\u001b[32m--> \u001b[39m\u001b[32m963\u001b[39m     p = \u001b[43msubprocess\u001b[49m\u001b[43m.\u001b[49m\u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconversion_command\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstdin\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevnull\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstdout\u001b[49m\u001b[43m=\u001b[49m\u001b[43msubprocess\u001b[49m\u001b[43m.\u001b[49m\u001b[43mPIPE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstderr\u001b[49m\u001b[43m=\u001b[49m\u001b[43msubprocess\u001b[49m\u001b[43m.\u001b[49m\u001b[43mPIPE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    964\u001b[39m p_out, p_err = p.communicate()\n\u001b[32m    966\u001b[39m log_subprocess_output(p_out)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Python311\\Lib\\subprocess.py:1024\u001b[39m, in \u001b[36mPopen.__init__\u001b[39m\u001b[34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask, pipesize, process_group)\u001b[39m\n\u001b[32m   1020\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.text_mode:\n\u001b[32m   1021\u001b[39m             \u001b[38;5;28mself\u001b[39m.stderr = io.TextIOWrapper(\u001b[38;5;28mself\u001b[39m.stderr,\n\u001b[32m   1022\u001b[39m                     encoding=encoding, errors=errors)\n\u001b[32m-> \u001b[39m\u001b[32m1024\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_execute_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecutable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreexec_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclose_fds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1025\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mpass_fds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcwd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1026\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mstartupinfo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreationflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshell\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1027\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mp2cread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp2cwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1028\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mc2pread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc2pwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1029\u001b[39m \u001b[43m                        \u001b[49m\u001b[43merrread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1030\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mrestore_signals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1031\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mgid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mumask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1032\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mstart_new_session\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprocess_group\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1033\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[32m   1034\u001b[39m     \u001b[38;5;66;03m# Cleanup if the child failed starting.\u001b[39;00m\n\u001b[32m   1035\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mfilter\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m, (\u001b[38;5;28mself\u001b[39m.stdin, \u001b[38;5;28mself\u001b[39m.stdout, \u001b[38;5;28mself\u001b[39m.stderr)):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Python311\\Lib\\subprocess.py:1509\u001b[39m, in \u001b[36mPopen._execute_child\u001b[39m\u001b[34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, unused_restore_signals, unused_gid, unused_gids, unused_uid, unused_umask, unused_start_new_session, unused_process_group)\u001b[39m\n\u001b[32m   1507\u001b[39m \u001b[38;5;66;03m# Start the process\u001b[39;00m\n\u001b[32m   1508\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1509\u001b[39m     hp, ht, pid, tid = \u001b[43m_winapi\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCreateProcess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexecutable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1510\u001b[39m \u001b[43m                             \u001b[49m\u001b[38;5;66;43;03m# no special security\u001b[39;49;00m\n\u001b[32m   1511\u001b[39m \u001b[43m                             \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1512\u001b[39m \u001b[43m                             \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mclose_fds\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1513\u001b[39m \u001b[43m                             \u001b[49m\u001b[43mcreationflags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1514\u001b[39m \u001b[43m                             \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1515\u001b[39m \u001b[43m                             \u001b[49m\u001b[43mcwd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1516\u001b[39m \u001b[43m                             \u001b[49m\u001b[43mstartupinfo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1517\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m   1518\u001b[39m     \u001b[38;5;66;03m# Child is launched. Close the parent's copy of those pipe\u001b[39;00m\n\u001b[32m   1519\u001b[39m     \u001b[38;5;66;03m# handles that only the child should have open.  You need\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1522\u001b[39m     \u001b[38;5;66;03m# pipe will not close when the child process exits and the\u001b[39;00m\n\u001b[32m   1523\u001b[39m     \u001b[38;5;66;03m# ReadFile will hang.\u001b[39;00m\n\u001b[32m   1524\u001b[39m     \u001b[38;5;28mself\u001b[39m._close_pipe_fds(p2cread, p2cwrite,\n\u001b[32m   1525\u001b[39m                          c2pread, c2pwrite,\n\u001b[32m   1526\u001b[39m                          errread, errwrite)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [WinError 2] El sistema no puede encontrar el archivo especificado"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import whisper\n",
    "import sounddevice as sd\n",
    "import numpy as np\n",
    "import wave\n",
    "from pydub import AudioSegment\n",
    "\n",
    "# ðŸ”¹ Gravar Ã¡udio do microfone e salvar como WAV\n",
    "def record_audio(filename=\"output.wav\", duration=5, samplerate=44100):\n",
    "    print(\"ðŸŽ™ï¸ Gravando... Fale algo!\")\n",
    "    audio_data = sd.rec(int(duration * samplerate), samplerate=samplerate, channels=1, dtype=np.int16)\n",
    "    sd.wait()\n",
    "    \n",
    "    with wave.open(filename, \"wb\") as wf:\n",
    "        wf.setnchannels(1)\n",
    "        wf.setsampwidth(2)\n",
    "        wf.setframerate(samplerate)\n",
    "        wf.writeframes(audio_data.tobytes())\n",
    "    \n",
    "    print(f\"âœ… Ãudio salvo como {filename}\")\n",
    "    return filename\n",
    "\n",
    "# ðŸ”¹ Converter WAV para MP3\n",
    "def convert_to_mp3(wav_filename):\n",
    "    mp3_filename = wav_filename.replace(\".wav\", \".mp3\")\n",
    "    audio = AudioSegment.from_wav(wav_filename)\n",
    "    audio.export(mp3_filename, format=\"mp3\")\n",
    "    print(f\"ðŸŽµ Arquivo convertido para {mp3_filename}\")\n",
    "    return mp3_filename\n",
    "\n",
    "# ðŸ”¹ Transcrever Ã¡udio com Whisper\n",
    "def transcribe_audio(mp3_filename):\n",
    "    print(\"ðŸ“ Transcrevendo Ã¡udio...\")\n",
    "    model = whisper.load_model(\"small\", device=\"cpu\")  # Modelos: \"tiny\", \"base\", \"small\", \"medium\", \"large\"\n",
    "    result = model.transcribe(mp3_filename)\n",
    "    print(\"\\nðŸ“ Texto reconhecido:\")\n",
    "    print(result[\"text\"])\n",
    "\n",
    "# ðŸ”¹ Executar o processo completo\n",
    "if __name__ == \"__main__\":\n",
    "    wav_file = record_audio(duration=5)  # Grava por 5 segundos\n",
    "    mp3_file = convert_to_mp3(wav_file)  # Converte para MP3\n",
    "    transcribe_audio(wav_file)  # Transcreve com Whisper\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai-whisper in c:\\users\\eel20\\desktop\\sentiment-analysis-speech-emotion-recognition\\.venv\\lib\\site-packages (20240930)\n",
      "Requirement already satisfied: numba in c:\\users\\eel20\\desktop\\sentiment-analysis-speech-emotion-recognition\\.venv\\lib\\site-packages (from openai-whisper) (0.61.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\eel20\\desktop\\sentiment-analysis-speech-emotion-recognition\\.venv\\lib\\site-packages (from openai-whisper) (2.1.3)\n",
      "Requirement already satisfied: torch in c:\\users\\eel20\\desktop\\sentiment-analysis-speech-emotion-recognition\\.venv\\lib\\site-packages (from openai-whisper) (2.6.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\eel20\\desktop\\sentiment-analysis-speech-emotion-recognition\\.venv\\lib\\site-packages (from openai-whisper) (4.67.1)\n",
      "Requirement already satisfied: more-itertools in c:\\users\\eel20\\desktop\\sentiment-analysis-speech-emotion-recognition\\.venv\\lib\\site-packages (from openai-whisper) (10.6.0)\n",
      "Requirement already satisfied: tiktoken in c:\\users\\eel20\\desktop\\sentiment-analysis-speech-emotion-recognition\\.venv\\lib\\site-packages (from openai-whisper) (0.9.0)\n",
      "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in c:\\users\\eel20\\desktop\\sentiment-analysis-speech-emotion-recognition\\.venv\\lib\\site-packages (from numba->openai-whisper) (0.44.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\eel20\\desktop\\sentiment-analysis-speech-emotion-recognition\\.venv\\lib\\site-packages (from tiktoken->openai-whisper) (2024.11.6)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\users\\eel20\\desktop\\sentiment-analysis-speech-emotion-recognition\\.venv\\lib\\site-packages (from tiktoken->openai-whisper) (2.32.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\eel20\\desktop\\sentiment-analysis-speech-emotion-recognition\\.venv\\lib\\site-packages (from torch->openai-whisper) (3.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\eel20\\desktop\\sentiment-analysis-speech-emotion-recognition\\.venv\\lib\\site-packages (from torch->openai-whisper) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\eel20\\desktop\\sentiment-analysis-speech-emotion-recognition\\.venv\\lib\\site-packages (from torch->openai-whisper) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\eel20\\desktop\\sentiment-analysis-speech-emotion-recognition\\.venv\\lib\\site-packages (from torch->openai-whisper) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\eel20\\desktop\\sentiment-analysis-speech-emotion-recognition\\.venv\\lib\\site-packages (from torch->openai-whisper) (2025.3.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\eel20\\desktop\\sentiment-analysis-speech-emotion-recognition\\.venv\\lib\\site-packages (from torch->openai-whisper) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\eel20\\desktop\\sentiment-analysis-speech-emotion-recognition\\.venv\\lib\\site-packages (from sympy==1.13.1->torch->openai-whisper) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\eel20\\desktop\\sentiment-analysis-speech-emotion-recognition\\.venv\\lib\\site-packages (from tqdm->openai-whisper) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\eel20\\desktop\\sentiment-analysis-speech-emotion-recognition\\.venv\\lib\\site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\eel20\\desktop\\sentiment-analysis-speech-emotion-recognition\\.venv\\lib\\site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\eel20\\desktop\\sentiment-analysis-speech-emotion-recognition\\.venv\\lib\\site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\eel20\\desktop\\sentiment-analysis-speech-emotion-recognition\\.venv\\lib\\site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2025.1.31)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\eel20\\desktop\\sentiment-analysis-speech-emotion-recognition\\.venv\\lib\\site-packages (from jinja2->torch->openai-whisper) (3.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install openai-whisper "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grabando audio durante 5 segundos... Habla al micrÃ³fono.\n",
      "GrabaciÃ³n completada.\n",
      "Archivo guardado como: recorded_audio\\recording_20250309_204635.wav\n",
      "Para convertir a MP3 sin ffmpeg, instala 'lameenc' y descomenta la funciÃ³n save_as_mp3 abajo.\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import sounddevice as sd\n",
    "import numpy as np\n",
    "import scipy.io.wavfile as wavfile\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "def record_audio(duration=5, sample_rate=44100, channels=1):\n",
    "    \"\"\"\n",
    "    Graba audio desde el micrÃ³fono durante un tiempo especificado.\n",
    "    \n",
    "    Args:\n",
    "        duration (int): DuraciÃ³n de la grabaciÃ³n en segundos (por defecto 5).\n",
    "        sample_rate (int): Frecuencia de muestreo (por defecto 44100 Hz).\n",
    "        channels (int): NÃºmero de canales (1 para mono, 2 para estÃ©reo; por defecto 1).\n",
    "    \n",
    "    Returns:\n",
    "        numpy.ndarray: Datos de audio grabados.\n",
    "    \"\"\"\n",
    "    print(f\"Grabando audio durante {duration} segundos... Habla al micrÃ³fono.\")\n",
    "    \n",
    "    # Grabar audio\n",
    "    audio_data = sd.rec(int(duration * sample_rate), samplerate=sample_rate, channels=channels, dtype='float32')\n",
    "    sd.wait()  # Esperar hasta que la grabaciÃ³n termine\n",
    "    \n",
    "    print(\"GrabaciÃ³n completada.\")\n",
    "    return audio_data, sample_rate\n",
    "\n",
    "def save_as_wav(audio_data, sample_rate, output_path):\n",
    "    \"\"\"\n",
    "    Guarda los datos de audio en un archivo WAV.\n",
    "    \n",
    "    Args:\n",
    "        audio_data (numpy.ndarray): Datos de audio grabados.\n",
    "        sample_rate (int): Frecuencia de muestreo.\n",
    "        output_path (str): Ruta donde se guardarÃ¡ el archivo WAV.\n",
    "    \"\"\"\n",
    "    # Normalizar y convertir a int16\n",
    "    audio_data = (audio_data * 32768).astype(np.int16)\n",
    "    \n",
    "    # Guardar como WAV\n",
    "    wavfile.write(output_path, sample_rate, audio_data)\n",
    "    print(f\"Archivo guardado como: {output_path}\")\n",
    "\n",
    "def main():\n",
    "    # ConfiguraciÃ³n\n",
    "    duration = 5  # DuraciÃ³n en segundos\n",
    "    sample_rate = 44100  # Frecuencia de muestreo estÃ¡ndar\n",
    "    channels = 1  # Mono\n",
    "    \n",
    "    # Generar un nombre de archivo Ãºnico basado en la fecha y hora\n",
    "    timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    output_dir = \"recorded_audio\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    output_path = os.path.join(output_dir, f\"recording_{timestamp}.wav\")  # Guardamos como WAV\n",
    "    \n",
    "    # Grabar audio\n",
    "    audio_data, sample_rate = record_audio(duration, sample_rate, channels)\n",
    "    \n",
    "    # Guardar como WAV\n",
    "    save_as_wav(audio_data, sample_rate, output_path)\n",
    "\n",
    "    # Nota: Sin ffmpeg, no podemos convertir a MP3 directamente aquÃ­.\n",
    "    # Para MP3, necesitarÃ­as instalar lameenc o usar ffmpeg (recomendado).\n",
    "    print(\"Para convertir a MP3 sin ffmpeg, instala 'lameenc' y descomenta la funciÃ³n save_as_mp3 abajo.\")\n",
    "    # Descomenta y ajusta si instalas lameenc:\n",
    "    # from lameenc import Encoder\n",
    "    # save_as_mp3(audio_data, sample_rate, output_path.replace(\".wav\", \".mp3\"))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
