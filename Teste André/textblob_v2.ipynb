{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\andre\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing complete. Processed dataset saved as 'processed_dataset.csv'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Type</th>\n",
       "      <th>Factual/Subjective</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sky blue</td>\n",
       "      <td>Affirmation</td>\n",
       "      <td>Factual</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>love sunny day</td>\n",
       "      <td>Affirmation</td>\n",
       "      <td>Subjective</td>\n",
       "      <td>Happiness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pizza disgusting</td>\n",
       "      <td>Affirmation</td>\n",
       "      <td>Subjective</td>\n",
       "      <td>Anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>water boil 100 degree celsius</td>\n",
       "      <td>Affirmation</td>\n",
       "      <td>Factual</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dont think good idea</td>\n",
       "      <td>Negation</td>\n",
       "      <td>Subjective</td>\n",
       "      <td>Sadness</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Sentence         Type Factual/Subjective  Sentiment\n",
       "0                       sky blue  Affirmation            Factual    Neutral\n",
       "1                 love sunny day  Affirmation         Subjective  Happiness\n",
       "2               pizza disgusting  Affirmation         Subjective      Anger\n",
       "3  water boil 100 degree celsius  Affirmation            Factual    Neutral\n",
       "4           dont think good idea     Negation         Subjective    Sadness"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from textblob import TextBlob\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import string\n",
    "\n",
    "# Download necessary NLTK resources\n",
    "nltk.download('punkt_tab')\n",
    "#nltk.download('punkt')\n",
    "#nltk.download('stopwords')\n",
    "#nltk.download('wordnet')\n",
    "#nltk.download('omw-1.4')\n",
    "\n",
    "# Load dataset\n",
    "file_path = \"dataset.csv\"  # Change this to your actual dataset path\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Initialize tools\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "# Preprocessing function\n",
    "def preprocess_text(sentence):\n",
    "    sentence = sentence.lower()  # Convert to lowercase\n",
    "    sentence = sentence.translate(str.maketrans('', '', string.punctuation))  # Remove punctuation\n",
    "    words = word_tokenize(sentence)  # Tokenization\n",
    "    words = [lemmatizer.lemmatize(word) for word in words if word not in stop_words]  # Lemmatization & stopword removal\n",
    "    processed_sentence = \" \".join(words)\n",
    "    \n",
    "    # Extract TextBlob features\n",
    "    blob = TextBlob(processed_sentence)\n",
    "    polarity = blob.sentiment.polarity  # Sentiment polarity (-1 to 1)\n",
    "    subjectivity = blob.sentiment.subjectivity  # Subjectivity (0 = factual, 1 = subjective)\n",
    "    \n",
    "    return processed_sentence#, polarity, subjectivity\n",
    "\n",
    "# Apply preprocessing\n",
    "# Create a copy of the original dataframe\n",
    "df_processed = df.copy()\n",
    "\n",
    "# Apply preprocessing to the 'Sentence' column\n",
    "df_processed['Sentence'] = df['Sentence'].apply(preprocess_text)\n",
    "\n",
    "# Save processed data\n",
    "df_processed.to_csv(\"processed_dataset.csv\", index=False)\n",
    "\n",
    "print(\"Preprocessing complete. Processed dataset saved as 'processed_dataset.csv'\")\n",
    "df_processed.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "miaa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
