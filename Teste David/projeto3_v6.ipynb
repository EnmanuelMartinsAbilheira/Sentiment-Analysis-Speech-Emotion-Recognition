{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta versão: \n",
    "    -> corrige os erros todos (ortograficos e gramaticais)\n",
    "\n",
    "    -> vê a polarity e subjectivity com o textblob\n",
    "\n",
    "    -> avalia se a frase é negativa ou afirmativa \n",
    "            (utiliza a análise do spaCY para procurar palavras de negação como not, n't, never, ...)\n",
    "\n",
    "    -> avalia se a frase é factual ou uma opinião \n",
    "            (usa um modelo pre treinado, https://huggingface.co/lighteternal/fact-or-opinion-xlmr-el)\n",
    "\n",
    "                Label 0: Opinion/Subjective sentence\n",
    "                Label 1: Fact/Objective sentence\n",
    "\n",
    "    -> classifica a emoção \n",
    "            (usa um modelo pre treinado, https://huggingface.co/ayoubkirouane/BERT-Emotions-Classifier)\n",
    "            \n",
    "            este modelo tem 11 emoções:\n",
    "                'anger' \n",
    "                'anticipation'\n",
    "                'disgust'\n",
    "                'fear'\n",
    "                'joy'\n",
    "                'love'\n",
    "                'optimism'\n",
    "                'pessimism'\n",
    "                'sadness'\n",
    "                'surprise'\n",
    "                'trust'\n",
    "\n",
    "    -> vê inference times de todas as funções\n",
    "\n",
    "    -> Compara os resultados de modelos pré treinados com modelos feitos por nós"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import nltk\n",
    "import spacy\n",
    "import textblob\n",
    "from textblob import TextBlob\n",
    "from spellchecker import SpellChecker\n",
    "from gramformer import Gramformer\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\dhabid\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    nltk.data.find('tokenizers/punkt')\n",
    "except LookupError:\n",
    "    nltk.download('punkt')\n",
    "\n",
    "try:\n",
    "    nltk.data.find('corpora/wordnet')\n",
    "except LookupError:\n",
    "    nltk.download('wordnet')\n",
    "\n",
    "# Load spaCy model\n",
    "try:\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "except OSError:\n",
    "    print(\"Downloading spaCy model...\")\n",
    "    import os\n",
    "    os.system(\"python -m spacy download en_core_web_sm\")\n",
    "    nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ignore warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup the decorator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from types import MethodType\n",
    "\n",
    "def add_method(cls):\n",
    "    def decorator(func):\n",
    "        setattr(cls, func.__name__, func)\n",
    "        return func\n",
    "    return decorator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize pretrained models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextAnalyzer:\n",
    "    def __init__(self):\n",
    "        self.spell_checker = SpellChecker()\n",
    "        self.gramformer = Gramformer(models=1, use_gpu=False)\n",
    "        \n",
    "        # Initialize emotion classifier\n",
    "        print(\"Loading emotion classification model...\")\n",
    "        self.emotion_classifier = pipeline(\"text-classification\", \n",
    "        model=\"ayoubkirouane/BERT-Emotions-Classifier\", return_all_scores=True)\n",
    "\n",
    "        # Initialize specialized fact vs. opinion classifier with correct model name\n",
    "        print(\"Loading specialized fact-opinion classification model...\")\n",
    "        self.fact_opinion_classifier = pipeline(\n",
    "            \"text-classification\",\n",
    "            model=\"lighteternal/fact-or-opinion-xlmr-el\"\n",
    "        )\n",
    "        \n",
    "        # For storing timing information\n",
    "        self.inference_times = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize custom models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "@add_method(TextAnalyzer)\n",
    "def load_custom_models(self):\n",
    "    \"\"\"Load custom trained models for comparison.\"\"\"\n",
    "    import pickle\n",
    "    from sentence_transformers import SentenceTransformer\n",
    "    from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "    \n",
    "    print(\"Loading custom models...\")\n",
    "    \n",
    "    # Load embedding model\n",
    "    try:\n",
    "        self.sentence_encoder = SentenceTransformer(\"sentence-transformers/all-mpnet-base-v2\")\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Could not load sentence encoder: {e}\")\n",
    "        self.sentence_encoder = None\n",
    "    \n",
    "    # Load TF-IDF vectorizer\n",
    "    try:\n",
    "        with open(\"tfidf_vectorizer.pkl\", \"rb\") as f:\n",
    "            self.tfidf_vectorizer = pickle.load(f)\n",
    "        print(\"Loaded TF-IDF vectorizer\")\n",
    "    except FileNotFoundError:\n",
    "        print(\"Warning: TF-IDF vectorizer not found. Will fit on first input.\")\n",
    "        self.tfidf_vectorizer = None\n",
    "    \n",
    "    # Load custom models\n",
    "    try:\n",
    "        with open(\"best_model_Type.pkl\", \"rb\") as f:\n",
    "            self.custom_type_model = pickle.load(f)\n",
    "        \n",
    "        with open(\"best_model_Factuality.pkl\", \"rb\") as f:\n",
    "            self.custom_fact_model = pickle.load(f)\n",
    "            \n",
    "        with open(\"best_model_Sentiment.pkl\", \"rb\") as f:\n",
    "            self.custom_sentiment_model = pickle.load(f)\n",
    "            \n",
    "        # Define mappings for results\n",
    "        self.type_labels = {0: \"affirmative\", 1: \"negation\"}\n",
    "        self.factuality_labels = {0: \"fact\", 1: \"opinion\"}\n",
    "        self.sentiment_labels = {0: \"sadness\", 1: \"anger\", 2: \"neutral\", 3: \"happiness\", 4: \"euphoria\"}\n",
    "        \n",
    "        print(\"Custom models loaded successfully\")\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"Error loading custom models: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "@add_method(TextAnalyzer)\n",
    "def preprocess_text_for_custom_models(self, text, model_type=None):\n",
    "    \"\"\"\n",
    "    Preprocess text for custom models using the appropriate feature extraction method.\n",
    "    \n",
    "    Args:\n",
    "        text: The text to preprocess\n",
    "        model_type: Which model this is for ('type', 'factuality', 'sentiment'), to determine correct featurization\n",
    "    \"\"\"\n",
    "    # If we're using TF-IDF vectorizer (needed for factuality model)\n",
    "    if model_type == 'factuality' or self.sentence_encoder is None:\n",
    "        if self.tfidf_vectorizer:\n",
    "            return self.tfidf_vectorizer.transform([text])\n",
    "        else:\n",
    "            # Create and fit a new vectorizer if needed\n",
    "            from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "            self.tfidf_vectorizer = TfidfVectorizer(max_features=5000)\n",
    "            self.tfidf_vectorizer.fit([text])\n",
    "            print(\"Note: Fitted vectorizer on first input (this is not optimal for production)\")\n",
    "            return self.tfidf_vectorizer.transform([text])\n",
    "    \n",
    "    # Otherwise use sentence embeddings\n",
    "    try:\n",
    "        return self.sentence_encoder.encode([text])\n",
    "    except Exception as e:\n",
    "        print(f\"Error with sentence embeddings: {e}, falling back to TF-IDF\")\n",
    "        if self.tfidf_vectorizer:\n",
    "            return self.tfidf_vectorizer.transform([text])\n",
    "        else:\n",
    "            # Create and fit a new vectorizer if needed\n",
    "            from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "            self.tfidf_vectorizer = TfidfVectorizer(max_features=5000)\n",
    "            self.tfidf_vectorizer.fit([text])\n",
    "            print(\"Note: Fitted vectorizer on first input (this is not optimal for production)\")\n",
    "            return self.tfidf_vectorizer.transform([text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "@add_method(TextAnalyzer)\n",
    "def custom_predict_type(self, text):\n",
    "    \"\"\"Predict sentence type (affirmative/negative) using custom model.\"\"\"\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Try with sentence embeddings first\n",
    "    try:\n",
    "        if self.sentence_encoder:\n",
    "            text_features = self.sentence_encoder.encode([text])\n",
    "            prediction = self.custom_type_model.predict(text_features)[0]\n",
    "        else:\n",
    "            raise ValueError(\"Sentence encoder not available\")\n",
    "    except Exception as e:\n",
    "        # Fall back to TF-IDF if sentence embeddings fail\n",
    "        text_features = self.preprocess_text_for_custom_models(text, model_type='type')\n",
    "        prediction = self.custom_type_model.predict(text_features)[0]\n",
    "    \n",
    "    sentence_type = self.type_labels[prediction]\n",
    "    \n",
    "    elapsed_time = time.time() - start_time\n",
    "    self.inference_times['custom_type_detection'] = elapsed_time\n",
    "    \n",
    "    return sentence_type, elapsed_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "@add_method(TextAnalyzer)\n",
    "def custom_predict_factuality(self, text):\n",
    "    \"\"\"Predict factuality (fact/opinion) using custom model.\"\"\"\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Always use TF-IDF for factuality model since it expects 2754 features\n",
    "    text_features = self.preprocess_text_for_custom_models(text, model_type='factuality')\n",
    "    \n",
    "    # Make prediction\n",
    "    prediction = self.custom_fact_model.predict(text_features)[0]\n",
    "    factuality = self.factuality_labels[prediction]\n",
    "    \n",
    "    elapsed_time = time.time() - start_time\n",
    "    self.inference_times['custom_factuality_detection'] = elapsed_time\n",
    "    \n",
    "    return factuality, elapsed_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "@add_method(TextAnalyzer)\n",
    "def custom_predict_emotion(self, text):\n",
    "    \"\"\"Predict emotion using custom model.\"\"\"\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Try with sentence embeddings first\n",
    "    try:\n",
    "        if self.sentence_encoder:\n",
    "            text_features = self.sentence_encoder.encode([text])\n",
    "            prediction = self.custom_sentiment_model.predict(text_features)[0]\n",
    "        else:\n",
    "            raise ValueError(\"Sentence encoder not available\")\n",
    "    except Exception as e:\n",
    "        # Fall back to TF-IDF if sentence embeddings fail\n",
    "        text_features = self.preprocess_text_for_custom_models(text, model_type='sentiment')\n",
    "        prediction = self.custom_sentiment_model.predict(text_features)[0]\n",
    "    \n",
    "    emotion = self.sentiment_labels[prediction]\n",
    "    \n",
    "    elapsed_time = time.time() - start_time\n",
    "    self.inference_times['custom_emotion_detection'] = elapsed_time\n",
    "    \n",
    "    return emotion, elapsed_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimized Gramformer for sentence correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "@add_method(TextAnalyzer)\n",
    "def correct_spelling(self, sentence):\n",
    "    start_time = time.time()\n",
    "    words = sentence.split() \n",
    "    corrected_words = [self.spell_checker.correction(word) or word for word in words] \n",
    "    result = \" \".join(corrected_words)\n",
    "    elapsed_time = time.time() - start_time\n",
    "    self.inference_times['spell_correction'] = elapsed_time\n",
    "    return result\n",
    "\n",
    "@add_method(TextAnalyzer)\n",
    "def correct_sentence(self, sentence):\n",
    "    start_time = time.time()\n",
    "    spelled_corrected = self.correct_spelling(sentence)\n",
    "    \n",
    "    # Separate timing for grammar correction\n",
    "    grammar_start_time = time.time()\n",
    "    corrected_sentences = self.gramformer.correct(spelled_corrected, max_candidates=1)\n",
    "    result = next(iter(corrected_sentences), spelled_corrected)\n",
    "    grammar_elapsed_time = time.time() - grammar_start_time\n",
    "    \n",
    "    elapsed_time = time.time() - start_time\n",
    "    self.inference_times['grammar_correction'] = grammar_elapsed_time\n",
    "    self.inference_times['total_correction'] = elapsed_time\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polarity detection with Spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "@add_method(TextAnalyzer)\n",
    "def analyze_sentence_type(self, text):\n",
    "    \"\"\"Determine if the sentence is affirmative or negative\"\"\"\n",
    "    start_time = time.time()\n",
    "    doc = nlp(text)\n",
    "    \n",
    "    # Check for negation\n",
    "    has_negation = any(token.dep_ == 'neg' for token in doc)\n",
    "    \n",
    "    # Determine sentence type\n",
    "    if has_negation:\n",
    "        sentence_type = \"negation\"\n",
    "    else:\n",
    "        sentence_type = \"affirmative\"\n",
    "    \n",
    "    elapsed_time = time.time() - start_time\n",
    "    self.inference_times['sentence_type_analysis'] = elapsed_time\n",
    "    \n",
    "    return {\n",
    "        'sentence_type': sentence_type\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subjectivity detection with a pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "@add_method(TextAnalyzer)\n",
    "def classify_fact_opinion(self, text):\n",
    "    \"\"\"Classify if the text is a fact or an opinion using a specialized model.\"\"\"\n",
    "    start_time = time.time()\n",
    "    result = self.fact_opinion_classifier(text)[0]\n",
    "    \n",
    "    # This model outputs LABEL_0 (opinion) or LABEL_1 (fact)\n",
    "    # Convert to more readable format\n",
    "    label_map = {\"LABEL_0\": \"opinion\", \"LABEL_1\": \"fact\"}\n",
    "    classification = label_map.get(result['label'], result['label'])\n",
    "    confidence = result['score']\n",
    "    \n",
    "    elapsed_time = time.time() - start_time\n",
    "    self.inference_times['fact_opinion_classification'] = elapsed_time\n",
    "    \n",
    "    return {\n",
    "        'classification': classification,\n",
    "        'confidence': confidence\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Emotion classification with DistilBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "@add_method(TextAnalyzer)\n",
    "def detect_emotion(self, text):\n",
    "    \"\"\"Detects emotions in text using the BERT-Emotions-Classifier model.\"\"\"\n",
    "    start_time = time.time()\n",
    "    emotion_scores = self.emotion_classifier(text)[0]\n",
    "    sorted_emotions = sorted(emotion_scores, key=lambda x: x['score'], reverse=True)\n",
    "    top_emotion = sorted_emotions[0]\n",
    "    all_emotions = {emotion['label']: emotion['score'] for emotion in sorted_emotions}\n",
    "    \n",
    "    elapsed_time = time.time() - start_time\n",
    "    self.inference_times['emotion_detection'] = elapsed_time\n",
    "    \n",
    "    return {\"emotion\": top_emotion['label'], \"confidence\": top_emotion['score'], \"all_emotions\": all_emotions}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of the given text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "@add_method(TextAnalyzer)\n",
    "def analyze_text(self, text):\n",
    "    \"\"\"Complete analysis of the given text.\"\"\"\n",
    "    # Reset timing data for new analysis\n",
    "    self.inference_times = {}\n",
    "    \n",
    "    total_start_time = time.time()\n",
    "    \n",
    "    original_text = text\n",
    "    corrected_text = self.correct_sentence(text)\n",
    "    \n",
    "    sentence_params = self.analyze_sentence_type(corrected_text)\n",
    "    emotion_data = self.detect_emotion(corrected_text)\n",
    "    fact_opinion_data = self.classify_fact_opinion(corrected_text)\n",
    "    \n",
    "    total_elapsed_time = time.time() - total_start_time\n",
    "    self.inference_times['total_analysis'] = total_elapsed_time\n",
    "    \n",
    "    result = {\n",
    "        'original_text': original_text,\n",
    "        'corrected_text': corrected_text,\n",
    "        'needs_correction': original_text != corrected_text,\n",
    "        'sentence_type': sentence_params['sentence_type'],\n",
    "        'emotion': emotion_data['emotion'],\n",
    "        'emotion_confidence': emotion_data['confidence'],\n",
    "        'all_emotions': emotion_data['all_emotions'],\n",
    "        'fact_opinion': fact_opinion_data['classification'],\n",
    "        'fact_opinion_confidence': fact_opinion_data['confidence'],\n",
    "        'inference_times': self.inference_times\n",
    "    }\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "@add_method(TextAnalyzer)\n",
    "def compare_models(self, text):\n",
    "    \"\"\"Compare custom models with pretrained models on the same text.\"\"\"\n",
    "    # First correct any spelling/grammar issues in the text\n",
    "    corrected_text = self.correct_sentence(text)\n",
    "    \n",
    "    # Get predictions and timing from pretrained models\n",
    "    type_result = self.analyze_sentence_type(corrected_text)\n",
    "    pretrained_type = type_result[\"sentence_type\"]\n",
    "    \n",
    "    emotion_result = self.detect_emotion(corrected_text)\n",
    "    pretrained_emotion = emotion_result[\"emotion\"]\n",
    "    \n",
    "    factuality_result = self.classify_fact_opinion(corrected_text)\n",
    "    pretrained_factuality = factuality_result[\"classification\"]\n",
    "    \n",
    "    # Get predictions and timing from custom models\n",
    "    custom_type, custom_type_time = self.custom_predict_type(corrected_text)\n",
    "    custom_emotion, custom_emotion_time = self.custom_predict_emotion(corrected_text)\n",
    "    custom_factuality, custom_factuality_time = self.custom_predict_factuality(corrected_text)\n",
    "    \n",
    "    # Collect pretrained model timing info\n",
    "    pretrained_type_time = self.inference_times.get('sentence_type_analysis', 0)\n",
    "    pretrained_emotion_time = self.inference_times.get('emotion_detection', 0)\n",
    "    pretrained_factuality_time = self.inference_times.get('fact_opinion_classification', 0)\n",
    "    \n",
    "    # Return comparison results\n",
    "    return {\n",
    "        'text': text,\n",
    "        'corrected_text': corrected_text,\n",
    "        'type': {\n",
    "            'pretrained': pretrained_type,\n",
    "            'custom': custom_type,\n",
    "            'time_pretrained': pretrained_type_time,\n",
    "            'time_custom': custom_type_time,\n",
    "            'time_difference': pretrained_type_time - custom_type_time,\n",
    "            'time_ratio': pretrained_type_time / custom_type_time if custom_type_time > 0 else float('inf')\n",
    "        },\n",
    "        'factuality': {\n",
    "            'pretrained': pretrained_factuality,\n",
    "            'custom': custom_factuality,\n",
    "            'time_pretrained': pretrained_factuality_time,\n",
    "            'time_custom': custom_factuality_time,\n",
    "            'time_difference': pretrained_factuality_time - custom_factuality_time,\n",
    "            'time_ratio': pretrained_factuality_time / custom_factuality_time if custom_factuality_time > 0 else float('inf')\n",
    "        },\n",
    "        'emotion': {\n",
    "            'pretrained': pretrained_emotion,\n",
    "            'custom': custom_emotion,\n",
    "            'time_pretrained': pretrained_emotion_time,\n",
    "            'time_custom': custom_emotion_time,\n",
    "            'time_difference': pretrained_emotion_time - custom_emotion_time,\n",
    "            'time_ratio': pretrained_emotion_time / custom_emotion_time if custom_emotion_time > 0 else float('inf')\n",
    "        }\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentence classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Gramformer] Grammar error correct/highlight model loaded..\n",
      "Loading emotion classification model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading specialized fact-opinion classification model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading custom models...\n",
      "Loaded TF-IDF vectorizer\n",
      "Custom models loaded successfully\n",
      "Model Comparison Tool\n",
      "---------------------\n",
      "Enter a sentence to analyze with both pre-trained and custom models (or 'quit' to exit):\n",
      "\n",
      "================================================================================\n",
      "COMPARISON RESULTS FOR: 'Nicole rides her bike in the afternoon'\n",
      "================================================================================\n",
      "Corrected text: 'Nicole rides her bike in the afternoon.'\n",
      "\n",
      "------------------------------ SENTENCE TYPE ------------------------------\n",
      "Pretrained model: affirmative (0.0199s)\n",
      "Custom model:     affirmative (0.1567s)\n",
      "Time difference:  0.1368s (custom is slower)\n",
      "Agreement:        ✓\n",
      "\n",
      "------------------------------ FACTUALITY ------------------------------\n",
      "Pretrained model: fact (0.1578s)\n",
      "Custom model:     opinion (0.0020s)\n",
      "Time difference:  0.1558s (pretrained is slower)\n",
      "Agreement:        ✗\n",
      "\n",
      "------------------------------ EMOTION ------------------------------\n",
      "Pretrained model: joy (0.2518s)\n",
      "Custom model:     neutral (0.0795s)\n",
      "Time difference:  0.1723s (pretrained is slower)\n",
      "Agreement:        ✗\n",
      "\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "COMPARISON RESULTS FOR: 'I don't know when I'll be traveling unfortunately'\n",
      "================================================================================\n",
      "Corrected text: 'I don't know when I'll be traveling unfortunately.'\n",
      "\n",
      "------------------------------ SENTENCE TYPE ------------------------------\n",
      "Pretrained model: negation (0.0116s)\n",
      "Custom model:     negation (0.0537s)\n",
      "Time difference:  0.0421s (custom is slower)\n",
      "Agreement:        ✓\n",
      "\n",
      "------------------------------ FACTUALITY ------------------------------\n",
      "Pretrained model: opinion (0.0544s)\n",
      "Custom model:     opinion (0.0010s)\n",
      "Time difference:  0.0534s (pretrained is slower)\n",
      "Agreement:        ✓\n",
      "\n",
      "------------------------------ EMOTION ------------------------------\n",
      "Pretrained model: sadness (0.0979s)\n",
      "Custom model:     neutral (0.0550s)\n",
      "Time difference:  0.0429s (pretrained is slower)\n",
      "Agreement:        ✗\n",
      "\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "COMPARISON RESULTS FOR: 'Fortunately not all the students failed'\n",
      "================================================================================\n",
      "Corrected text: 'Fortunately, not all the students failed.'\n",
      "\n",
      "------------------------------ SENTENCE TYPE ------------------------------\n",
      "Pretrained model: negation (0.0080s)\n",
      "Custom model:     affirmative (0.0949s)\n",
      "Time difference:  0.0869s (custom is slower)\n",
      "Agreement:        ✗\n",
      "\n",
      "------------------------------ FACTUALITY ------------------------------\n",
      "Pretrained model: fact (0.0876s)\n",
      "Custom model:     fact (0.0010s)\n",
      "Time difference:  0.0866s (pretrained is slower)\n",
      "Agreement:        ✓\n",
      "\n",
      "------------------------------ EMOTION ------------------------------\n",
      "Pretrained model: optimism (0.0791s)\n",
      "Custom model:     neutral (0.0891s)\n",
      "Time difference:  0.0100s (custom is slower)\n",
      "Agreement:        ✗\n",
      "\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def display_comparison_results(results):\n",
    "    \"\"\"Display formatted comparison results between models.\"\"\"\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"COMPARISON RESULTS FOR: '{results['text']}'\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    if results['text'] != results['corrected_text']:\n",
    "        print(f\"Corrected text: '{results['corrected_text']}'\")\n",
    "    \n",
    "    # Type comparison\n",
    "    print(f\"\\n{'-'*30} SENTENCE TYPE {'-'*30}\")\n",
    "    print(f\"Pretrained model: {results['type']['pretrained']} ({results['type']['time_pretrained']:.4f}s)\")\n",
    "    print(f\"Custom model:     {results['type']['custom']} ({results['type']['time_custom']:.4f}s)\")\n",
    "    print(f\"Time difference:  {abs(results['type']['time_difference']):.4f}s \" + \n",
    "          f\"({'pretrained' if results['type']['time_difference'] > 0 else 'custom'} is slower)\")\n",
    "    print(f\"Agreement:        {'✓' if results['type']['pretrained'] == results['type']['custom'] else '✗'}\")\n",
    "    \n",
    "    # Factuality comparison\n",
    "    print(f\"\\n{'-'*30} FACTUALITY {'-'*30}\")\n",
    "    print(f\"Pretrained model: {results['factuality']['pretrained']} ({results['factuality']['time_pretrained']:.4f}s)\")\n",
    "    print(f\"Custom model:     {results['factuality']['custom']} ({results['factuality']['time_custom']:.4f}s)\")\n",
    "    print(f\"Time difference:  {abs(results['factuality']['time_difference']):.4f}s \" + \n",
    "          f\"({'pretrained' if results['factuality']['time_difference'] > 0 else 'custom'} is slower)\")\n",
    "    print(f\"Agreement:        {'✓' if results['factuality']['pretrained'] == results['factuality']['custom'] else '✗'}\")\n",
    "    \n",
    "    # Emotion comparison\n",
    "    print(f\"\\n{'-'*30} EMOTION {'-'*30}\")\n",
    "    print(f\"Pretrained model: {results['emotion']['pretrained']} ({results['emotion']['time_pretrained']:.4f}s)\")\n",
    "    print(f\"Custom model:     {results['emotion']['custom']} ({results['emotion']['time_custom']:.4f}s)\")\n",
    "    print(f\"Time difference:  {abs(results['emotion']['time_difference']):.4f}s \" + \n",
    "          f\"({'pretrained' if results['emotion']['time_difference'] > 0 else 'custom'} is slower)\")\n",
    "    print(f\"Agreement:        {'✓' if results['emotion']['pretrained'] == results['emotion']['custom'] else '✗'}\")\n",
    "    \n",
    "    print(f\"\\n{'='*80}\\n\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    analyzer = TextAnalyzer()\n",
    "    analyzer.load_custom_models()\n",
    "    \n",
    "    print(\"Model Comparison Tool\")\n",
    "    print(\"---------------------\")\n",
    "    print(\"Enter a sentence to analyze with both pre-trained and custom models (or 'quit' to exit):\")\n",
    "    \n",
    "    while True:\n",
    "        user_input = input(\"\\nYour sentence: \")\n",
    "        if user_input.lower() == 'quit':\n",
    "            break\n",
    "        \n",
    "        comparison_results = analyzer.compare_models(user_input)\n",
    "        display_comparison_results(comparison_results)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mia",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
