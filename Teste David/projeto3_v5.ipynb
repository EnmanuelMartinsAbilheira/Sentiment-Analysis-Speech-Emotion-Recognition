{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta versão: \n",
    "    -> corrige os erros todos (ortograficos e gramaticais)\n",
    "\n",
    "    -> vê a polarity e subjectivity com o textblob\n",
    "\n",
    "    -> avalia se a frase é negativa ou afirmativa \n",
    "            (utiliza a análise do spaCY para procurar palavras de negação como not, n't, never, ...)\n",
    "\n",
    "    -> avalia se a frase é factual ou uma opinião \n",
    "            (usa um modelo pre treinado, https://huggingface.co/lighteternal/fact-or-opinion-xlmr-el)\n",
    "\n",
    "                Label 0: Opinion/Subjective sentence\n",
    "                Label 1: Fact/Objective sentence\n",
    "\n",
    "    -> classifica a emoção \n",
    "            (usa um modelo pre treinado, https://huggingface.co/ayoubkirouane/BERT-Emotions-Classifier)\n",
    "            \n",
    "            este modelo tem 11 emoções:\n",
    "                'anger' \n",
    "                'anticipation'\n",
    "                'disgust'\n",
    "                'fear'\n",
    "                'joy'\n",
    "                'love'\n",
    "                'optimism'\n",
    "                'pessimism'\n",
    "                'sadness'\n",
    "                'surprise'\n",
    "                'trust'\n",
    "\n",
    "    -> vê inference times de todas as funções"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import nltk\n",
    "import spacy\n",
    "import textblob\n",
    "from textblob import TextBlob\n",
    "from spellchecker import SpellChecker\n",
    "from gramformer import Gramformer\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\dhabid\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    nltk.data.find('tokenizers/punkt')\n",
    "except LookupError:\n",
    "    nltk.download('punkt')\n",
    "\n",
    "try:\n",
    "    nltk.data.find('corpora/wordnet')\n",
    "except LookupError:\n",
    "    nltk.download('wordnet')\n",
    "\n",
    "# Load spaCy model\n",
    "try:\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "except OSError:\n",
    "    print(\"Downloading spaCy model...\")\n",
    "    import os\n",
    "    os.system(\"python -m spacy download en_core_web_sm\")\n",
    "    nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ignore warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup the decorator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from types import MethodType\n",
    "\n",
    "def add_method(cls):\n",
    "    def decorator(func):\n",
    "        setattr(cls, func.__name__, func)\n",
    "        return func\n",
    "    return decorator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextAnalyzer:\n",
    "    def __init__(self):\n",
    "        self.spell_checker = SpellChecker()\n",
    "        self.gramformer = Gramformer(models=1, use_gpu=False)\n",
    "        \n",
    "        # Initialize emotion classifier\n",
    "        print(\"Loading emotion classification model...\")\n",
    "        self.emotion_classifier = pipeline(\"text-classification\", \n",
    "        model=\"ayoubkirouane/BERT-Emotions-Classifier\", return_all_scores=True)\n",
    "\n",
    "        # Initialize specialized fact vs. opinion classifier with correct model name\n",
    "        print(\"Loading specialized fact-opinion classification model...\")\n",
    "        self.fact_opinion_classifier = pipeline(\n",
    "            \"text-classification\",\n",
    "            model=\"lighteternal/fact-or-opinion-xlmr-el\"\n",
    "        )\n",
    "        \n",
    "        # For storing timing information\n",
    "        self.inference_times = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimized Gramformer for sentence correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "@add_method(TextAnalyzer)\n",
    "def correct_spelling(self, sentence):\n",
    "    start_time = time.time()\n",
    "    words = sentence.split() \n",
    "    corrected_words = [self.spell_checker.correction(word) or word for word in words] \n",
    "    result = \" \".join(corrected_words)\n",
    "    elapsed_time = time.time() - start_time\n",
    "    self.inference_times['spell_correction'] = elapsed_time\n",
    "    return result\n",
    "\n",
    "@add_method(TextAnalyzer)\n",
    "def correct_sentence(self, sentence):\n",
    "    start_time = time.time()\n",
    "    spelled_corrected = self.correct_spelling(sentence)\n",
    "    \n",
    "    # Separate timing for grammar correction\n",
    "    grammar_start_time = time.time()\n",
    "    corrected_sentences = self.gramformer.correct(spelled_corrected, max_candidates=1)\n",
    "    result = next(iter(corrected_sentences), spelled_corrected)\n",
    "    grammar_elapsed_time = time.time() - grammar_start_time\n",
    "    \n",
    "    elapsed_time = time.time() - start_time\n",
    "    self.inference_times['grammar_correction'] = grammar_elapsed_time\n",
    "    self.inference_times['total_correction'] = elapsed_time\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polarity detection with Spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "@add_method(TextAnalyzer)\n",
    "def analyze_sentence_type(self, text):\n",
    "    \"\"\"Determine if the sentence is affirmative or negative\"\"\"\n",
    "    start_time = time.time()\n",
    "    doc = nlp(text)\n",
    "    \n",
    "    # Check for negation\n",
    "    has_negation = any(token.dep_ == 'neg' for token in doc)\n",
    "    \n",
    "    # Determine sentence type\n",
    "    if has_negation:\n",
    "        sentence_type = \"negation\"\n",
    "    else:\n",
    "        sentence_type = \"affirmative\"\n",
    "    \n",
    "    elapsed_time = time.time() - start_time\n",
    "    self.inference_times['sentence_type_analysis'] = elapsed_time\n",
    "    \n",
    "    return {\n",
    "        'sentence_type': sentence_type\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subjectivity detection with a pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "@add_method(TextAnalyzer)\n",
    "def classify_fact_opinion(self, text):\n",
    "    \"\"\"Classify if the text is a fact or an opinion using a specialized model.\"\"\"\n",
    "    start_time = time.time()\n",
    "    result = self.fact_opinion_classifier(text)[0]\n",
    "    \n",
    "    # This model outputs LABEL_0 (opinion) or LABEL_1 (fact)\n",
    "    # Convert to more readable format\n",
    "    label_map = {\"LABEL_0\": \"opinion\", \"LABEL_1\": \"fact\"}\n",
    "    classification = label_map.get(result['label'], result['label'])\n",
    "    confidence = result['score']\n",
    "    \n",
    "    elapsed_time = time.time() - start_time\n",
    "    self.inference_times['fact_opinion_classification'] = elapsed_time\n",
    "    \n",
    "    return {\n",
    "        'classification': classification,\n",
    "        'confidence': confidence\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Emotion classification with DistilBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "@add_method(TextAnalyzer)\n",
    "def detect_emotion(self, text):\n",
    "    \"\"\"Detects emotions in text using the BERT-Emotions-Classifier model.\"\"\"\n",
    "    start_time = time.time()\n",
    "    emotion_scores = self.emotion_classifier(text)[0]\n",
    "    sorted_emotions = sorted(emotion_scores, key=lambda x: x['score'], reverse=True)\n",
    "    top_emotion = sorted_emotions[0]\n",
    "    all_emotions = {emotion['label']: emotion['score'] for emotion in sorted_emotions}\n",
    "    \n",
    "    elapsed_time = time.time() - start_time\n",
    "    self.inference_times['emotion_detection'] = elapsed_time\n",
    "    \n",
    "    return {\"emotion\": top_emotion['label'], \"confidence\": top_emotion['score'], \"all_emotions\": all_emotions}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of the given text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "@add_method(TextAnalyzer)\n",
    "def analyze_text(self, text):\n",
    "    \"\"\"Complete analysis of the given text.\"\"\"\n",
    "    # Reset timing data for new analysis\n",
    "    self.inference_times = {}\n",
    "    \n",
    "    total_start_time = time.time()\n",
    "    \n",
    "    original_text = text\n",
    "    corrected_text = self.correct_sentence(text)\n",
    "    \n",
    "    sentence_params = self.analyze_sentence_type(corrected_text)\n",
    "    emotion_data = self.detect_emotion(corrected_text)\n",
    "    fact_opinion_data = self.classify_fact_opinion(corrected_text)\n",
    "    \n",
    "    total_elapsed_time = time.time() - total_start_time\n",
    "    self.inference_times['total_analysis'] = total_elapsed_time\n",
    "    \n",
    "    result = {\n",
    "        'original_text': original_text,\n",
    "        'corrected_text': corrected_text,\n",
    "        'needs_correction': original_text != corrected_text,\n",
    "        'sentence_type': sentence_params['sentence_type'],\n",
    "        'emotion': emotion_data['emotion'],\n",
    "        'emotion_confidence': emotion_data['confidence'],\n",
    "        'all_emotions': emotion_data['all_emotions'],\n",
    "        'fact_opinion': fact_opinion_data['classification'],\n",
    "        'fact_opinion_confidence': fact_opinion_data['confidence'],\n",
    "        'inference_times': self.inference_times\n",
    "    }\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentence classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Gramformer] Grammar error correct/highlight model loaded..\n",
      "Loading emotion classification model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading specialized fact-opinion classification model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Analysis Tool\n",
      "------------------\n",
      "Enter a sentence to analyze (or 'quit' to exit):\n",
      "\n",
      "Analysis Results:\n",
      "-----------------\n",
      "Corrected: Nicole rides her bike.\n",
      "---\n",
      "Sentence type: affirmative\n",
      "Classification: fact (confidence: 1.00)\n",
      "Emotion detected: joy (confidence: 0.85)\n",
      "\n",
      "All detected emotions and their confidence scores:\n",
      "-> joy: 0.85\n",
      "-> optimism: 0.43\n",
      "-> love: 0.08\n",
      "-> anticipation: 0.08\n",
      "-> sadness: 0.07\n",
      "-> trust: 0.02\n",
      "-> pessimism: 0.02\n",
      "-> disgust: 0.02\n",
      "-> surprise: 0.01\n",
      "-> anger: 0.01\n",
      "-> fear: 0.01\n",
      "\n",
      "Inference Times:\n",
      "-----------------\n",
      "-> spell_correction: 0.0000 seconds\n",
      "-> grammar_correction: 0.9778 seconds\n",
      "-> total_correction: 0.9778 seconds\n",
      "-> sentence_type_analysis: 0.0104 seconds\n",
      "-> emotion_detection: 0.1546 seconds\n",
      "-> fact_opinion_classification: 0.1409 seconds\n",
      "-> total_analysis: 1.2836 seconds\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    analyzer = TextAnalyzer()\n",
    "    \n",
    "    print(\"Text Analysis Tool\")\n",
    "    print(\"------------------\")\n",
    "    print(\"Enter a sentence to analyze (or 'quit' to exit):\")\n",
    "    \n",
    "    while True:\n",
    "        user_input = input(\"\\nYour sentence: \")\n",
    "        if user_input.lower() == 'quit':\n",
    "            break\n",
    "        \n",
    "        result = analyzer.analyze_text(user_input)\n",
    "        \n",
    "        print(\"\\nAnalysis Results:\")\n",
    "        print(\"-----------------\")\n",
    "        if result['needs_correction']:\n",
    "            print(f\"Corrected: {result['corrected_text']}\")\n",
    "            \n",
    "        print(\"---\")\n",
    "        print(f\"Sentence type: {result['sentence_type']}\")\n",
    "        print(f\"Classification: {result['fact_opinion']} (confidence: {result['fact_opinion_confidence']:.2f})\")\n",
    "        print(f\"Emotion detected: {result['emotion']} (confidence: {result['emotion_confidence']:.2f})\")\n",
    "        \n",
    "        print(\"\\nAll detected emotions and their confidence scores:\")\n",
    "        for emotion, score in result['all_emotions'].items():\n",
    "            print(f\"-> {emotion}: {score:.2f}\")\n",
    "        \n",
    "        # Display inference times\n",
    "        print(\"\\nInference Times:\")\n",
    "        print(\"-----------------\")\n",
    "        for operation, time_taken in result['inference_times'].items():\n",
    "            print(f\"-> {operation}: {time_taken:.4f} seconds\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mia",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
