{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "csv_path = \"E:\\Github\\Sentiment-Analysis-Speech-Emotion-Recognition\\Dataset\\dataset.csv\"  # Update this path\n",
    "df = pd.read_csv(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize sentence embedding model\n",
    "model = SentenceTransformer(\"sentence-transformers/all-mpnet-base-v2\")\n",
    "\n",
    "# Encode sentences into embeddings\n",
    "embeddings = model.encode(df[\"Sentence\"].tolist())\n",
    "\n",
    "# Label encoding\n",
    "type_mapping = {\"Affirmation\": 0, \"Negation\": 1}\n",
    "fact_subj_mapping = {\"Factual\": 0, \"Subjective\": 1}\n",
    "sentiment_mapping = {\"Sadness\": 0, \"Anger\": 1, \"Neutral\": 2, \"Happiness\": 3, \"Euphoria\": 4}\n",
    "\n",
    "df[\"Type\"] = df[\"Type\"].map(type_mapping).fillna(-1).astype(int)\n",
    "df[\"Factual/Subjective\"] = df[\"Factual/Subjective\"].map(fact_subj_mapping).fillna(-1).astype(int)\n",
    "df[\"Sentiment\"] = df[\"Sentiment\"].map(sentiment_mapping).fillna(-1).astype(int)\n",
    "\n",
    "# Convert labels to NumPy arrays\n",
    "type_labels = df[\"Type\"].values\n",
    "fact_subj_labels = df[\"Factual/Subjective\"].values\n",
    "sentiment_labels = df[\"Sentiment\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stratified Train-Test Split (based on Sentiment)\n",
    "X_train, X_test, y_type_train, y_type_test, y_fact_train, y_fact_test, y_sent_train, y_sent_test = train_test_split(\n",
    "    embeddings, type_labels, fact_subj_labels, sentiment_labels,\n",
    "    test_size=0.2, random_state=42, stratify=sentiment_labels\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter Grid for Logistic Regression\n",
    "logistic_param_grid = {\"C\": [0.01, 0.1, 1, 10, 100]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_logistic_regression(X_train, y_train, X_test, y_test, name):\n",
    "    model = LogisticRegression(max_iter=1000)\n",
    "    grid_search = GridSearchCV(model, logistic_param_grid, cv=3, scoring=\"accuracy\", n_jobs=-1)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    best_model = grid_search.best_estimator_\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    print(f\"Best Logistic Regression Model for {name}: {grid_search.best_params_}\")\n",
    "    print(f\"Accuracy for {name}: {acc:.4f}\\n\")\n",
    "    \n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Logistic Regression Model for Type Classification: {'C': 10}\n",
      "Accuracy for Type Classification: 0.9490\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate logistic regression models\n",
    "type_model = train_logistic_regression(X_train, y_type_train, X_test, y_type_test, \"Type Classification\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Logistic Regression Model for Factual/Subjective Classification: {'C': 100}\n",
      "Accuracy for Factual/Subjective Classification: 0.9388\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate logistic regression models\n",
    "fact_model = train_logistic_regression(X_train, y_fact_train, X_test, y_fact_test, \"Factual/Subjective Classification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter Grid for XGBoost\n",
    "xgb_param_grid = {\n",
    "    \"n_estimators\": [100, 200, 500],\n",
    "    \"max_depth\": [3, 5, 7],\n",
    "    \"learning_rate\": [0.01, 0.1, 0.3],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_xgboost(X_train, y_train, X_test, y_test, name):\n",
    "    model = XGBClassifier(eval_metric=\"mlogloss\")\n",
    "    grid_search = GridSearchCV(model, xgb_param_grid, cv=3, scoring=\"accuracy\", n_jobs=-1)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    best_model = grid_search.best_estimator_\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    print(f\"Best XGBoost Model for {name}: {grid_search.best_params_}\")\n",
    "    print(f\"Accuracy for {name}: {acc:.4f}\\n\")\n",
    "    \n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best XGBoost Model for Sentiment Classification: {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 500}\n",
      "Accuracy for Sentiment Classification: 0.8878\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate XGBoost model\n",
    "sentiment_model = train_xgboost(X_train, y_sent_train, X_test, y_sent_test, \"Sentiment Classification\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save Logistic Regression models\n",
    "with open(\"type_model.pkl\", \"wb\") as f:\n",
    "    pickle.dump(type_model, f)\n",
    "\n",
    "with open(\"fact_model.pkl\", \"wb\") as f:\n",
    "    pickle.dump(fact_model, f)\n",
    "\n",
    "# Save XGBoost model\n",
    "with open(\"sentiment_model.pkl\", \"wb\") as f:\n",
    "    pickle.dump(sentiment_model, f)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MIAA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
