{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, RNN, LSTMCell\n",
    "from tensorflow.keras.callbacks import EarlyStopping, LearningRateScheduler, ReduceLROnPlateau\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(dataset_path, img_size=(128, 128)):\n",
    "    \"\"\"\n",
    "    Loads precomputed mel-spectrogram images and extracts labels from folder names.\n",
    "    \"\"\"\n",
    "    X = []\n",
    "    y = []\n",
    "    class_names = sorted(os.listdir(dataset_path))  # Get emotion categories\n",
    "    \n",
    "    for label in class_names:\n",
    "        class_path = os.path.join(dataset_path, label)\n",
    "        if not os.path.isdir(class_path):\n",
    "            continue\n",
    "        \n",
    "        files = glob.glob(os.path.join(class_path, '*.png'))\n",
    "        print(f\"Found {len(files)} images for class '{label}'.\")\n",
    "        \n",
    "        for file in files:\n",
    "            img = cv2.imread(file, cv2.IMREAD_GRAYSCALE)  # Load in grayscale\n",
    "            img = cv2.resize(img, img_size)  # Resize to standard size\n",
    "            X.append(img)\n",
    "            y.append(label)\n",
    "    \n",
    "    X = np.array(X, dtype=np.float32) / 255.0  # Normalize pixel values\n",
    "    y = np.array(y)\n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_labels(y):\n",
    "    \"\"\"Encodes string labels into numerical one-hot vectors.\"\"\"\n",
    "    le = LabelEncoder()\n",
    "    y_encoded = le.fit_transform(y)\n",
    "    y_onehot = to_categorical(y_encoded)\n",
    "    return y_onehot, le\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(input_shape, num_classes):\n",
    "    \"\"\"\n",
    "    Builds and returns an LSTM model using RNN wrappers with LSTMCell.\n",
    "    This forces the non-cuDNN implementation, which is compatible with DirectML on AMD GPUs.\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    # First LSTM layer using LSTMCell wrapped in an RNN\n",
    "    model.add(RNN(LSTMCell(128), return_sequences=True, input_shape=input_shape))\n",
    "    model.add(Dropout(0.2))\n",
    "    # Second LSTM layer using LSTMCell wrapped in an RNN\n",
    "    model.add(RNN(LSTMCell(64)))\n",
    "    model.add(Dropout(0.2))\n",
    "    # Fully connected layers for classification\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scheduler(epoch, lr):\n",
    "    return lr * 0.5 if epoch > 0 and epoch % 100 == 0 else lr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    dataset_path = 'RAVDESS_mel_spectrograms'  # Update with your dataset path\n",
    "    X, y = load_data(dataset_path)\n",
    "    # For the LSTM model, each spectrogram is treated as a sequence of 128 timesteps with 128 features.\n",
    "    # No extra channel dimension is added.\n",
    "    \n",
    "    y_onehot, le = preprocess_labels(y)\n",
    "    \n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X, y_onehot, test_size=0.2, random_state=42, stratify=np.argmax(y_onehot, axis=1)\n",
    "    )\n",
    "    \n",
    "    input_shape = X_train.shape[1:]  # Expected to be (128, 128)\n",
    "    num_classes = y_onehot.shape[1]\n",
    "    model = build_model(input_shape, num_classes)\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    early_stop = EarlyStopping(monitor='val_loss', patience=200, restore_best_weights=True)\n",
    "    lr_scheduler = LearningRateScheduler(scheduler)\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=100, min_lr=1e-6)\n",
    "    \n",
    "    model.fit(\n",
    "        X_train, y_train, \n",
    "        epochs=2000, \n",
    "        batch_size=32, \n",
    "        validation_data=(X_val, y_val),\n",
    "        callbacks=[early_stop, lr_scheduler, reduce_lr]\n",
    "    )\n",
    "    \n",
    "    loss, acc = model.evaluate(X_val, y_val)\n",
    "    print(f\"Validation Loss: {loss:.4f}, Validation Accuracy: {acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "proj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
