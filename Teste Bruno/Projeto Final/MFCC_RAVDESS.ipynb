{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping from the third pair of numbers to emotion label for RAVDESS\n",
    "emotion_map = {\n",
    "    '01': 'neutral',\n",
    "    '02': 'calm',\n",
    "    '03': 'happy',\n",
    "    '04': 'sad',\n",
    "    '05': 'angry',\n",
    "    '06': 'fearful',\n",
    "    '07': 'disgust',\n",
    "    '08': 'surprised',\n",
    "    'N': 'neutral'  # In case an 'N' is used instead of \"01\" for neutral\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mel_spectrogram(audio_path, output_path):\n",
    "    \"\"\"\n",
    "    Loads an audio file, computes its mel-spectrogram,\n",
    "    saves the resulting image, then crops the image based on a fixed bounding box.\n",
    "    \"\"\"\n",
    "    # Load the audio file at its native sampling rate\n",
    "    y, sr = librosa.load(audio_path, sr=None)\n",
    "    # Compute the mel-spectrogram with 128 mel bands\n",
    "    S = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128)\n",
    "    # Convert to log scale (dB)\n",
    "    S_dB = librosa.power_to_db(S, ref=np.max)\n",
    "    \n",
    "    # Create a plot for the spectrogram\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    librosa.display.specshow(S_dB, sr=sr, x_axis='time', y_axis='mel')\n",
    "    plt.title(f\"Mel-Spectrogram for {os.path.basename(audio_path)}\")\n",
    "    plt.colorbar(format='%+2.0f dB')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save the figure as a PNG file\n",
    "    plt.savefig(output_path)\n",
    "    plt.close()\n",
    "    \n",
    "    # Crop the image according to the bounding box:\n",
    "    # Top left corner (80, 37) with width 725 and height 305 pixels.\n",
    "    left = 90\n",
    "    top = 37\n",
    "    right = left + 715\n",
    "    bottom = top + 305\n",
    "    \n",
    "    with Image.open(output_path) as img:\n",
    "        cropped_img = img.crop((left, top, right, bottom))\n",
    "        cropped_img.save(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dataset(dataset_path, output_base):\n",
    "    \"\"\"\n",
    "    Recursively processes each WAV file in the dataset folder and its subfolders.\n",
    "    For each file:\n",
    "      - Determines the emotion based on the third pair of numbers in its filename.\n",
    "      - Creates an output folder for that emotion if it doesn't exist.\n",
    "      - Converts the audio to a mel-spectrogram image, then crops it.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(output_base):\n",
    "        os.makedirs(output_base)\n",
    "    \n",
    "    # Walk through the dataset folder and its subdirectories\n",
    "    for root, _, files in os.walk(dataset_path):\n",
    "        for filename in files:\n",
    "            if filename.lower().endswith('.wav'):\n",
    "                file_path = os.path.join(root, filename)\n",
    "                base_name = os.path.splitext(filename)[0]\n",
    "                parts = base_name.split('-')\n",
    "                \n",
    "                # Check if the filename has at least three parts to extract emotion code\n",
    "                if len(parts) < 3:\n",
    "                    print(f\"Skipping {filename}: filename does not have enough parts to extract emotion code.\")\n",
    "                    continue\n",
    "                \n",
    "                # Get the third pair (index 2) as the emotion code\n",
    "                emotion_code = parts[2]\n",
    "                emotion = emotion_map.get(emotion_code)\n",
    "                \n",
    "                if emotion is None:\n",
    "                    print(f\"Skipping {filename}: unrecognized emotion code '{emotion_code}'.\")\n",
    "                    continue\n",
    "                \n",
    "                # Create an output directory for this emotion if needed\n",
    "                emotion_dir = os.path.join(output_base, emotion)\n",
    "                if not os.path.exists(emotion_dir):\n",
    "                    os.makedirs(emotion_dir)\n",
    "                \n",
    "                output_filename = f\"{base_name}.png\"\n",
    "                output_filepath = os.path.join(emotion_dir, output_filename)\n",
    "                \n",
    "                print(f\"Processing {filename} -> {output_filename} (Emotion: {emotion})\")\n",
    "                create_mel_spectrogram(file_path, output_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Path to the RAVDESS dataset folder (which contains several subfolders with WAV files)\n",
    "    dataset_folder = \"RAVDESS\"\n",
    "    # Base folder where the mel-spectrogram images will be saved (one folder per emotion)\n",
    "    output_folder = \"RAVDESS_mel_spectrograms\"\n",
    "    \n",
    "    process_dataset(dataset_folder, output_folder)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MIAA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
