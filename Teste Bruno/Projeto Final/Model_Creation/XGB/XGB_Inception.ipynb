{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import xgboost as xgb\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 535 files belonging to 7 classes.\n",
      "Using 428 files for training.\n",
      "Found 535 files belonging to 7 classes.\n",
      "Using 107 files for validation.\n",
      "Class names: ['anger', 'anxiety', 'boredom', 'disgust', 'happiness', 'neutral', 'sadness']\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# Parameters and Dataset Loading\n",
    "# -----------------------------\n",
    "data_dir = \"EmoDB_mel_spectrograms\"  # Base directory; must have one subfolder per class\n",
    "batch_size = 32\n",
    "img_size = (299, 299)  # InceptionV3 expects 299x299 images\n",
    "seed = 123\n",
    "\n",
    "# Load raw datasets with an 80/20 train-validation split\n",
    "raw_train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    seed=seed,\n",
    "    image_size=img_size,\n",
    "    batch_size=batch_size\n",
    ")\n",
    "raw_val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    seed=seed,\n",
    "    image_size=img_size,\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "# Save class names before caching and prefetching\n",
    "class_names = raw_train_ds.class_names\n",
    "print(\"Class names:\", class_names)\n",
    "\n",
    "# For performance, cache and prefetch the datasets\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "train_ds = raw_train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = raw_val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# CNN for Feature Extraction using InceptionV3\n",
    "# -----------------------------\n",
    "# Load a pretrained InceptionV3 model (without its top layers)\n",
    "base_model = InceptionV3(weights=\"imagenet\", include_top=False, input_shape=(img_size[0], img_size[1], 3))\n",
    "# Add a global average pooling layer to convert convolutional features into a flat embedding vector\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "feature_extractor = Model(inputs=base_model.input, outputs=x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting features for training set...\n",
      "1/1 [==============================] - 1s 731ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 1s 593ms/step\n",
      "Extracting features for validation set...\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Training embeddings shape: (428, 2048)\n",
      "Validation embeddings shape: (107, 2048)\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# Function to Extract Embeddings\n",
    "# -----------------------------\n",
    "def get_embeddings(dataset, model):\n",
    "    \"\"\"\n",
    "    Iterates over the dataset to extract CNN embeddings.\n",
    "    Preprocesses the images for InceptionV3 and collects embeddings and labels.\n",
    "    \"\"\"\n",
    "    embeddings = []\n",
    "    labels = []\n",
    "    for batch_images, batch_labels in dataset:\n",
    "        # Preprocess images for InceptionV3\n",
    "        batch_images = preprocess_input(batch_images)\n",
    "        # Get the embeddings for the batch\n",
    "        batch_emb = model.predict(batch_images)\n",
    "        embeddings.append(batch_emb)\n",
    "        labels.append(batch_labels.numpy())\n",
    "    return np.vstack(embeddings), np.hstack(labels)\n",
    "\n",
    "print(\"Extracting features for training set...\")\n",
    "X_train, y_train = get_embeddings(train_ds, feature_extractor)\n",
    "print(\"Extracting features for validation set...\")\n",
    "X_val, y_val = get_embeddings(val_ds, feature_extractor)\n",
    "\n",
    "print(\"Training embeddings shape:\", X_train.shape)\n",
    "print(\"Validation embeddings shape:\", X_val.shape)\n",
    "\n",
    "# Ensure labels are integers\n",
    "y_train = y_train.astype(np.int32)\n",
    "y_val = y_val.astype(np.int32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting hyperparameter optimization with RandomizedSearchCV...\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# XGBoost Classification with Hyperparameter Optimization via RandomizedSearchCV\n",
    "# -----------------------------\n",
    "num_classes = len(class_names)\n",
    "\n",
    "# Define the parameter grid for random search\n",
    "param_dist = {\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2, 0.3],\n",
    "    'max_depth': [5, 7, 9, 11],\n",
    "    'n_estimators': [200, 300, 500, 1000],\n",
    "    'subsample': [0.5, 0.7, 0.9, 1.0],\n",
    "    'colsample_bytree': [0.5, 0.7, 0.9, 1.0],\n",
    "    'gamma': [0, 0.1, 0.5, 1, 5]\n",
    "}\n",
    "\n",
    "# Initialize the base XGBoost classifier\n",
    "base_clf = xgb.XGBClassifier(\n",
    "    objective=\"multi:softmax\",\n",
    "    num_class=num_classes,\n",
    "    eval_metric=\"mlogloss\",\n",
    "    use_label_encoder=False\n",
    ")\n",
    "\n",
    "# Setup RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=base_clf,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=50,                # Number of parameter settings that are sampled\n",
    "    scoring='accuracy',\n",
    "    cv=5,                     # 3-fold cross-validation\n",
    "    verbose=1,\n",
    "    random_state=seed,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "print(\"Starting hyperparameter optimization with RandomizedSearchCV...\")\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"\\nBest Hyperparameters Found:\")\n",
    "print(random_search.best_params_)\n",
    "\n",
    "# Get the best estimator\n",
    "best_clf = random_search.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -----------------------------\n",
    "# Evaluation on Validation Set\n",
    "# -----------------------------\n",
    "y_pred = best_clf.predict(X_val)\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "print(\"\\nValidation Accuracy: {:.2f}%\".format(accuracy * 100))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_val, y_pred, target_names=class_names))\n",
    "\n",
    "# Plot the confusion matrix\n",
    "cm = confusion_matrix(y_val, y_pred)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(len(class_names))\n",
    "plt.xticks(tick_marks, class_names, rotation=45)\n",
    "plt.yticks(tick_marks, class_names)\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MIAA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
